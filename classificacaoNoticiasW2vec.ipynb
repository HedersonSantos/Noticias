{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classificacaoNoticiasW2vec",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HedersonSantos/Noticias/blob/main/classificacaoNoticiasW2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ntCB_ZoYIR"
      },
      "source": [
        "#https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794 (medio)\n",
        "#https://www.kdnuggets.com/2018/11/multi-class-text-classification-model-comparison-selection.html/2 (fraco)\n",
        "#https://realpython.com/python-keras-text-classification/ (fraco)\n",
        "#https://sabber.medium.com/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b (fraco)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool, Process\n",
        "import multiprocessing as mp\n",
        "from google.colab import files, drive\n",
        "from pathlib import Path\n",
        "import io, os\n",
        "import pickle\n",
        "import pyarrow.parquet as pq\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "\n",
        "import nltk, re\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import gensim\n",
        "import gensim.downloader as gensim_api\n",
        "\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import cross_val_score, KFold, RandomizedSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "from sklearn import feature_selection\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, \\\n",
        "                            recall_score, confusion_matrix, \\\n",
        "                            plot_confusion_matrix, classification_report, \\\n",
        "                            balanced_accuracy_score, cohen_kappa_score, matthews_corrcoef, \\\n",
        "                            auc, roc_curve, precision_recall_curve\n",
        "\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATJaqnNUqr_L"
      },
      "source": [
        "# Obtendo dataset de noticias tratadas em preProcessamento_noticias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnmIRw0WowrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66639374-b49c-445f-8362-f19bd689673c"
      },
      "source": [
        "#!rm news.*\n",
        "#!wget https://raw.githubusercontent.com/HedersonSantos/Noticias/main/news.zip\n",
        "#!unzip news.zip\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/Colab\\ Notebooks/\n",
        "!ls -lh \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/Colab Notebooks\n",
            "total 931K\n",
            "drwx------ 2 root root 4.0K Aug 31 12:22  amostra_news_integrada\n",
            "-rw------- 1 root root  57K Jul 13 19:50  artigosWikibr.ipynb\n",
            "drwx------ 2 root root 4.0K Aug 30 22:59  bertimbau\n",
            "-rw------- 1 root root  37K Aug  1 23:19 'BERTimbau_com_amostras (1).ipynb'\n",
            "-rw------- 1 root root 158K Sep  2 16:41  BERTimbau_com_amostras.ipynb\n",
            "drwx------ 2 root root 4.0K Aug  7 13:00  bertimbau_resp\n",
            "drwx------ 2 root root 4.0K Sep  1 13:17  classica_resp\n",
            "-rw------- 1 root root  82K Sep  5 21:04  classificacaoNoticiasW2vec\n",
            "-rw------- 1 root root 170K Aug  7 17:47 'Cópia de BERTimbau_Testes (1).ipynb'\n",
            "-rw------- 1 root root  98K Aug  7 15:29 'Cópia de BERTimbau_Testes (2).ipynb'\n",
            "-rw------- 1 root root  72K Aug  1 12:19 'Cópia de BERTimbau_Testes (3).ipynb'\n",
            "-rw------- 1 root root  46K Aug  1 11:45 'Cópia de BERTimbau_Testes (4).ipynb'\n",
            "-rw------- 1 root root 168K Aug 23 20:02 'Cópia de BERTimbau_Testes.ipynb'\n",
            "drwx------ 2 root root 4.0K Aug 16 22:40  figuras\n",
            "-rw------- 1 root root 9.7K Aug 16 23:41  ResultadosExperimentos.ipynb\n",
            "-rw------- 1 root root  306 Jul 12 18:08  Untitled\n",
            "-rw------- 1 root root 9.5K Sep  2 18:02  Untitled0.ipynb\n",
            "-rw------- 1 root root 1.2K Jul 12 17:26  Untitled1.ipynb\n",
            "-rw------- 1 root root 2.3K Sep  3 11:25  Untitled2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsW44sgpaDj-",
        "outputId": "62ded7cd-7f38-49bb-a5a1-0cf30b444218"
      },
      "source": [
        "%cd /gdrive/My\\ Drive/Colab\\ Notebooks/\n",
        "!ls ./amostra_news_integrada/amostra_5\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/Colab Notebooks\n",
            "test.csv  train.csv  valid.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CQJzsnkYJz_",
        "outputId": "a5fbde8e-a30a-41e9-aeb8-8d2b206b7f1a"
      },
      "source": [
        "mp.cpu_count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWX1z5Ntq-Ec"
      },
      "source": [
        "# Funções para processamento de Linguagem Natural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmvLl_wTrFR9"
      },
      "source": [
        "def download_pt_stopWords():\n",
        "\n",
        "  '''download das stopwords '''\n",
        "  nltk.download('stopwords') #stopwords\n",
        "  nltk.download('rslp')  #stemming\n",
        "        \n",
        "def removeStopWords( texto, excluirWords:list=None):\n",
        "  '''remove as stopwords do texto. Novas stopwords podem ser adicionadas através da lista excluirWords'''\n",
        "  naoQueridas = nltk.corpus.stopwords.words('portuguese')\n",
        "  if not excluirWords==None:\n",
        "    naoQueridas.extend(excluirWords)\n",
        "  naoQueridas = list(set(naoQueridas))\n",
        "  palavras = [i for i in texto.split() if not i.lower() in naoQueridas]\n",
        "  return (\" \".join(palavras))\n",
        "\n",
        "def aplicaStemming( texto):\n",
        "  ''' obtém o radical das palavras do vocabulário'''\n",
        "  stemmer = nltk.stem.RSLPStemmer()\n",
        "  palavras = []\n",
        "  for w in texto.split():\n",
        "      palavras.append(stemmer.stem(w))\n",
        "  return (\" \".join(palavras))\n",
        "\n",
        "def removeCaracteresNaoDesejados(texto):\n",
        "  textoLimpo = re.sub(r\"http\\S+\", \"\", texto)\n",
        "  textoLimpo = re.sub(r\"www\\..+\\..+\", \"\", texto)\n",
        "  textoLimpo = re.sub(r\"[^a-zA-ZáÁéÉíÍóÓúÚãÃàÀôâÂêÊôÔçÇ ]\", \"\", texto)\n",
        "  return textoLimpo\n",
        "\n",
        "def retornaVetorizacao(X,pct_min=1, pct_max=1, n_grams=(1,1), excluirSW:list=None, vetorPalavras=None, n_top=None):\n",
        "  ''' monta a matriz sparsa com o índice de vocabulário em cada texto. \n",
        "    Retorna a matriz sparsa e o vocabulário '''\n",
        "  if vetorPalavras==None:\n",
        "    count_vect = CountVectorizer(min_df=pct_min, max_df=pct_max, lowercase=True,stop_words=excluirSW, ngram_range=n_grams, max_features=n_top) \n",
        "  else:\n",
        "    count_vect = CountVectorizer(min_df=pct_min, max_df=pct_max, lowercase=True,stop_words=excluirSW, ngram_range=n_grams, vocabulary=vetorPalavras, max_features=n_top)\n",
        "  matriz_sparsa = count_vect.fit_transform(X)\n",
        "  vocabulario = count_vect.fit(X).vocabulary_\n",
        "  return [matriz_sparsa,vocabulario]\n",
        "\n",
        "def retornaMatriztfIdf(V):\n",
        "    ''' em cada documento, calcula o tf-idf de cada palavra\n",
        "        term frequency - inverse document frequency'''\n",
        "    tfidf_transformer = TfidfTransformer()\n",
        "    matriz_tfidf = tfidf_transformer.fit_transform(V)\n",
        "    return matriz_tfidf\n",
        "\n",
        "def reduzDimensionalidadecomPCA( X, nro_dimensao,UT=None):\n",
        "    data_pca= PCA(nro_dimensao)\n",
        "    if UT==None:\n",
        "        UT = data_pca.fit(X)\n",
        "    X_pca =  UT.fit_transform(X)\n",
        "      \n",
        "    return [UT,X_pca]\n",
        "\n",
        "def padronizaValores(X):\n",
        "  X_norm = StandardScaler(with_mean=False).fit_transform(X)\n",
        "  return X_norm\n",
        "\n",
        "def retornaPalavras(listaTexto:list):\n",
        "  words=\"\"\n",
        "  for i in listaTexto: \n",
        "    i = str(i) \n",
        "    separate = i.split() \n",
        "    for j in range(len(separate)): \n",
        "        separate[j] = separate[j].lower() \n",
        "  words += \" \".join(separate)+\" \"\n",
        "  return words\n",
        "def montaWordCloud(words, n_palavras:int, sw=None):\n",
        "  wc = WordCloud(width = 400, height = 200, \n",
        "                background_color ='black', max_words=n_palavras,\n",
        "                min_font_size = 10, stopwords = sw).generate(words)\n",
        "  return wc\n",
        "\n",
        "def imprimiWordCloud(listaTexto:list, n_palavras:int, cluster:str=None, sw=None):\n",
        "  words = retornaPalavras(listaTexto)\n",
        "  wc = montaWordCloud(words, n_palavras, sw)\n",
        "  plt.figure(figsize = (8, 8), facecolor = None) \n",
        "  plt.imshow(wc) \n",
        "  plt.axis(\"off\") \n",
        "  plt.tight_layout(pad = 0) \n",
        "  if not cluster == None:\n",
        "    plt.title('PALAVRAS PARA O CLUSTER ' + cluster)\n",
        "  plt.show()\n",
        "\n",
        "def preProcessaTextos(dfDados):\n",
        "  download_pt_stopWords()\n",
        "  dfDados['text'] = dfDados['text'].astype('unicode')\n",
        "  dfDados['text'] = dfDados['text'].map(removeCaracteresNaoDesejados)\n",
        "  dfDados['text'] = dfDados['text'].map(removeStopWords)\n",
        "  dfDados['text'] = dfDados['text'].map(aplicaStemming)\n",
        "  return dfDados\n",
        "  \n",
        "\n",
        "def PreProcessamentoParalelo(df, n_jobs):\n",
        "  df_split = np.array_split(df,n_jobs)\n",
        "  pool = Pool(n_jobs)\n",
        "  resultado = pool.map(preProcessaTextos, df_split)\n",
        "  df = pd.concat(resultado, sort=False)\n",
        "  return df\n",
        "\n",
        "def processaVetorizacao(dfDados,min_fr=0.01, max_fr=0.7, ngrams=(1,1),n_top=None, localDestinoVocabulario=None, vocabulario=None):\n",
        "  arquivoVetores = 'count_vector.pkl'\n",
        "  if vocabulario != None:\n",
        "    vetorPalavras=vocabulario\n",
        "  elif localDestinoVocabulario==None or Path(localDestinoVocabulario+\"/\"+arquivoVetores).is_file()==False:\n",
        "    vetorPalavras=None\n",
        "  else:\n",
        "    vetorPalavras = carregaEstrutura(localDestinoVocabulario, arquivoVetores)\n",
        "    if not vetorPalavras:\n",
        "      vetorPalavras=None\n",
        "  X = dfDados['text'].values\n",
        "  vetores = retornaVetorizacao(X = X,pct_min = min_fr,pct_max = max_fr,n_grams = ngrams,vetorPalavras = vetorPalavras,n_top = n_top)\n",
        "  if localDestinoVocabulario!=None:\n",
        "    salvaEstrutura(vetores[1],localDestinoVocabulario,arquivoVetores)\n",
        "  V = vetores[0]\n",
        "  return vetores\n",
        "\n",
        "def calcula_especificidade(matriz_confusao):\n",
        "  FP = matriz_confusao.sum(axis=0) - np.diag(matriz_confusao) \n",
        "  FN = matriz_confusao.sum(axis=1) - np.diag(matriz_confusao)\n",
        "  VP = np.diag(matriz_confusao)\n",
        "  VN = matriz_confusao.sum() - (FP + FN + VP)\n",
        "  FP = FP.astype(float)\n",
        "  FN = FN.astype(float)\n",
        "  VP = VP.astype(float)\n",
        "  VN = VN.astype(float)\n",
        "  TVN = np.sum(VN)/(np.sum(VN) + np.sum(FP))\n",
        "  return TVN\n",
        "\n",
        "def calcula_especificidade_porClasse(matriz_confusao):\n",
        "  FP = matriz_confusao.sum(axis=0) - np.diag(matriz_confusao) \n",
        "  FN = matriz_confusao.sum(axis=1) - np.diag(matriz_confusao)\n",
        "  VP = np.diag(matriz_confusao)\n",
        "  VN = matriz_confusao.sum() - (FP + FN + VP)\n",
        "  FP = FP.astype(float)\n",
        "  FN = FN.astype(float)\n",
        "  VP = VP.astype(float)\n",
        "  VN = VN.astype(float)\n",
        "  TVN = (VN)/(VN + FP)\n",
        "  return TVN\n",
        "\n",
        "def calcula_GMean_multiclass(revocacao):\n",
        "   revoc = np.array(revocacao)\n",
        "   GMean = revoc.prod()**(1.0/len(revoc))\n",
        "   return GMean \n",
        "\n",
        "def elabora_relatorio_metricas(report, matriz_confusao):\n",
        "  espec = calcula_especificidade_porClasse(matriz_confusao) # calcula o valor da especificidade para cada classe\n",
        "  dfrep = pd.DataFrame(report).transpose() #transforma o conteúdo do classification_report em um dataframe pandas\n",
        "  dfrep_a = dfrep[:-3].copy() # separa as métricas de cada classe do valor da acurácia geral do modelo\n",
        "  dfrep_a['specificity'] = espec # inclui no dataframe o valor da especificidade\n",
        "  dfrep_b  = dfrep[dfrep.index=='accuracy'].copy() #obtem do dataframe somente o valor da acurácia\n",
        "  dfrep_b['specificity']=calcula_especificidade(matriz_confusao) # inclui o valor da especificidade geral de todas as classes\n",
        "  metricas = ['precision', 'recall', 'specificity', 'f1-score', 'support'] #organiza as métricas na ordem desejada\n",
        "  df = pd.concat([dfrep_a[metricas],dfrep_b[metricas]],sort=False) #concatena todos os valores em um único dataframe\n",
        "  df['support'] = df['support'].astype('int')\n",
        "  return df\n",
        "\n",
        "def imprimeMetricas(y_pred, y_true, caminho_destino):\n",
        "  relatorio = \"\"\n",
        "  print('Classification Report:')\n",
        "  n_classe = np.max(y_true)+1 #obtem o número de classes\n",
        "  report = classification_report(y_true, y_pred, labels=np.arange(0,n_classe), digits=4, output_dict=True) #gera o relatório de métricas\n",
        "  cm = confusion_matrix(y_true, y_pred, labels=np.arange(0,n_classe)) #gera a matriz de confusao\n",
        "  report = elabora_relatorio_metricas(report, cm) #inclui no relatorio a especificidade\n",
        "  \n",
        "  print(report)\n",
        "\n",
        "  acuracia_score = accuracy_score(y_true, y_pred)\n",
        "  cohen_kappa = cohen_kappa_score(y_true, y_pred,labels=np.arange(0,n_classe))\n",
        "  ccmatheus = matthews_corrcoef(y_true, y_pred)\n",
        "  Gmean = calcula_GMean_multiclass(report['recall'])\n",
        "  acuracia_balanceada = balanced_accuracy_score(y_true, y_pred)\n",
        "\n",
        "  print(\"Acurácia:\",acuracia_score)\n",
        "  print('Acurácia balanceada:',acuracia_balanceada)\n",
        "  print('GMean:', Gmean)\n",
        "  print('Cohen Kappa Score:', cohen_kappa)\n",
        "  print('Coef. Correlacao Matheus:', ccmatheus)\n",
        "  \n",
        "  y = caminho_destino.split('/')\n",
        "  arquivo = y[-1:][0].split('.')[0]\n",
        "  report.to_csv('/'.join(y[:-1]) + '/' + arquivo + \".csv\", index=None)\n",
        "  outrasMetricas  = \"Acurácia:\" + str(acuracia_score)\n",
        "  outrasMetricas  += '\\n Acurácia balanceada:' + str(acuracia_balanceada)\n",
        "  outrasMetricas  += '\\n GMean:' + str(Gmean)\n",
        "  outrasMetricas  += '\\n Cohen Kappa Score:' + str(cohen_kappa)\n",
        "  outrasMetricas  += '\\n Coef. Correlacao Matheus:' + str(ccmatheus)\n",
        "  \n",
        "  \n",
        "  salvaEstrutura(outrasMetricas, '/'.join(y[:-1]), y[-1:][0])\n",
        "  \n",
        "\n",
        "def salvaEstrutura(estrutura, local, arquivo):\n",
        "  print('***SALVANDO***')\n",
        "  print(local + \"/\" + arquivo)\n",
        "  pickle.dump(estrutura,open(local + \"/\" + arquivo,'wb'))\n",
        "\n",
        "def carregaEstrutura(local, arquivo):\n",
        "  estrutura = pickle.load(open(local + \"/\" + arquivo,'rb'))\n",
        "  return estrutura\n",
        "\n",
        "def obtemListasn_grams(corpus):\n",
        "  ''' transformar o texto das noticias em uma lista de n-grams. Usaremos uni-gramas, bi-gramas e tri-gramas '''\n",
        "  ## cria uma lista de uni-grams\n",
        "  lst_corpus = []\n",
        "  for string in corpus:\n",
        "    lst_words = string.split() #cria uma lista com as palavras da noticia\n",
        "    lst_grams = [\" \".join(lst_words[i:i+1]) \n",
        "                for i in range(0, len(lst_words), 1)] #gera uma lista de combinação palavra a palavra (1-ngram)\n",
        "    lst_corpus.append(lst_grams)\n",
        "\n",
        "  ## detect bigrams and trigrams\n",
        "  bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, \n",
        "                  delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "  bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
        "  trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], \n",
        "              delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "  trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)\n",
        "  return [lst_corpus, bigrams_detector, trigrams_detector]\n",
        "\n",
        "def tokenizar(lst_corpus, max_seq_length):\n",
        "  #Transformar o corpus pré-processado (lista de n-gramas: lst_corpous) em uma lista de sequência usando tensorflow/keras\n",
        "  #tokenizar o texto - monta um dicionário cujas chaves são as palavras do texto e o value é um identificador (sequencial) da palavra.\n",
        "  tokenizer = kprocessing.text.Tokenizer() \n",
        "  tokenizer.fit_on_texts (lst_corpus) \n",
        "  dic_vocabulary = tokenizer.word_index\n",
        "\n",
        "  #criar sequência - para cada noticia, obtem o id de cada palavra no vocabulário\n",
        "  lst_text2seq = tokenizer.texts_to_sequences (lst_corpus)\n",
        "\n",
        "  #sequencia preenchimento - transforma a lista em um array numpy e limita o tamanho do vetor de cada noticia. \n",
        "  #                          Usaremos limite de 128. Sequencias menores que estas são preenchidas para ficar com 128.\n",
        "  #                          Usaremos tanto o preenchimento (padding) quanto o corte (truncating) após as 128 palavras. \n",
        "  X = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
        "                                                maxlen = max_seq_length, padding = \"post\", truncating = \"post\")\n",
        "  return [X, lst_text2seq, dic_vocabulary]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_Sln_Vau32S"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n",
        "# Prepara dataset para classificação com algoritmos clássicos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ2xC0jmIIIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430689a4-b878-40a3-b289-5300177e0a3f"
      },
      "source": [
        "#dfDados = pd.read_csv('news_integradas.csv')\n",
        "dfTreino = pd.read_csv('./amostra_news_integrada/amostra_5/train.csv')\n",
        "dfvalidacao = pd.read_csv('./amostra_news_integrada/amostra_5/valid.csv')\n",
        "dfteste = pd.read_csv('./amostra_news_integrada/amostra_5/test.csv')\n",
        "dfteste = pd.concat([dfvalidacao, dfteste], sort=False)\n",
        "print(dfTreino.shape, dfteste.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15396, 2) (3849, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "1C8HtgdwILvc",
        "outputId": "2dfc340c-2459-49ec-f749-88f843b639c2"
      },
      "source": [
        "df = dfTreino['category_nro'].value_counts()\n",
        "print(dfTreino['category_nro'].unique().size)\n",
        "df.plot.bar(figsize=(14,10))\n",
        "#'politica', 'economia', 'esporte', 'mundo', 'ilustrada', 'midia', 'tecnologia', 'educação', 'saude', 'ciencia'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f39c258d750>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2StJlfb_vCMx",
        "outputId": "3fc0e631-9c03-416e-a549-14cb01fe1677"
      },
      "source": [
        "%%time\n",
        "#para w2vec está sem stemizacao\n",
        "dfPreProc = PreProcessamentoParalelo(dfTreino,mp.cpu_count())\n",
        "#dfPreProc = preProcessaTextos(dfTreino)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "CPU times: user 1.34 s, sys: 418 ms, total: 1.75 s\n",
            "Wall time: 3min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k3HMohJ3Dv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9bf5091c-5fac-4010-ee82-1eac698ed136"
      },
      "source": [
        "print(dfPreProc.shape)\n",
        "dfPreProc.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15396, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category_nro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pouco ano Vinicius Lanza encontrou reação choro prova resultou decepção Então anos isolouse vestiário mergulhou desolação profunda enquanto lágrimas corriam rosto míseros cinco centésimos Jogos Rio dentro próprio Estádio Aquático Olímpico poucos meses sediaria megaevento esportivo exemplo vida natação repleta viradas partir desta terça Lanza chance promover Trezentos setenta sete dias após frustração seletiva olímpica chega Troféu Maria Lenk primeiro grande evento natação nacional ciclo melhor tempo entrada m borboleta eliminatória final nesta terça torneio Parque Aquático Maria Lenk dentro Parque Olímpico classificatório Mundial Budapeste julho vai marcar passagem bastão geraçesThiago Pereira exemplo aposentouse abril enquanto país vê surgir nomes Lanza outros ter ido Jogos bom manter fogo brigar vaga final medalha Tóquio diz mineiro hoje anos representa Minas Tênis Clube Medalha prata Campeonato Mundial júnior Cingapura m borboleta Lanza adotou EUA base início Estabeleceuse Bloomington Estado Indiana onde passou nadar universidade local estudar veterinária instituição passou ser orientado Ray Looze técnico integrou seleção norteamericana Rio guru Lilly King Cody Miller Blake Pieroni todos medalhistas Jogos Nesta temporada nadador brasileiro eleito capitão time universitário Ray disse Vini queria Olimpíada agora olhar pra frente contou nadador vaga Budapeste deve corroborar técnico disse Perder Olimpíada cinco centésimos ainda machuca fez manter foco maior mudança atitude resumiu Luiz Altamir viveu experiência diferente Conseguiu classificação Jogos Rio provas m livre revezamento x m livre passou primeira fase ambas nadador reconhece aprendizado pode ser interessante rumo Olimpíada Tóquio objetivo agora neste ciclo tentar ficar melhores mundo preciso treinar bastante Natural Roraima transferiu Flamengo Pinheiros nesta temporada clube paulistano divide raia Gabriel Santos Jogos Rio nadou revezamento x m livre Pedro Cardona perdeu Olimpíada pouco ficou terceiro m peito boa marca Pinheiros readquiriu Cesar Cielo nadador vitorioso história país mudou filosofia Dispensou medalhes olímpicos Bruno Fratus João Lucca apostou nova safra Percebemos hora mudar mentalidade afirmou técnico principal clube Alberto Pinto Silva Outros bons valores estarão Troféu Maria Lenk Brandonn Almeida nadou m medley m livre Rio deve mudar EUA competição fundista Guilherme Costa abril bateu recorde sulamericano m livre espera estabelecerse expoentes geração confiante Maria Lenk conseguir melhorar tempo vou Mundial disse CRISE coisa abala confiança promessas situação turbulenta passa CBDA Confederação Brasileira Desportos Aquáticos Acusados corrupção quatro dirigentes presos meio entidade perdeu patrocínio Bradesco viu despencar aporte feito Correios investimento vai diminuir bastante vai ser dificuldade grande nova geração busca novas competiçes lá afirmou Luiz Altamir nadador disse espera nova gestão transparência melhor melhor maneira ter credibilidade novo mudar tudo Pensamento estratégia busca novos patrocinadores Renovar palavra certa complementou Altamir Vinícius Lanza acrise abateu sobre confederação triste vai afetar geração Sobre dirigentes presos afirmou Justiça decide eventos Troféu Maria Lenk TERÇAFEIRA Eliminatórias h finais h m borboleta Feminino Masculino m livre F M m peito F M x m livre F M QUARTAFEIRA Eliminatórias h finais h m costas F M m medley F M m livre F m livre M QUINTAFEIRA Eliminatórias h finais h m livre F M m peito FeM m costas F M m borboleta F M SEXTAFEIRA Eliminatórias h finais h m medley F M m livre F M m costas F M m borboleta F M x m livre F M SÁBADO Eliminatórias h finais h m peito F M m livre F M m livre F m livre M x m medley F M</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>situação financeira Paulo apesar restriçes despesas ligeiro aumento arrecadação registrado recentemente delicada secretário Fazenda Luis Arrobas Martins diz arrecadação ICM Imposto sobre Circulação Mercadorias primeiro semestre deveria ser NCr milhes R bilhes ficou NCr milhes R bilhes queda Além distanciar previsão orçamentária governo Estado reduziu desejava orçamentos Secretarias Educação Segurança Pública</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dezenas milhares pessoas participaram nesta quartafeira França dia protestos convocados sindicalistas estudantes contra reforma lei trabalhista país impulsionada governo ato resposta intenção presidente François Hollande permitir empresas mudar jornada trabalho funcionários além horas semanais determinadas lei remuneração adicional novo modelo trabalhadores poderão trabalhar horas diárias horas semanais seguir pactos sindicatos troca funcionários passarão receber folgas extras fazem parte reforma medidas reduzir regras demisses trabalho remoto noturno medida defendida governo forma reduzir taxa desemprego França manifestaçes reuniram trabalhadores desempregados estudantes responderam chamado sindicatos movimento estudantil protestaram cidades francesas Paris número manifestantes chegou mil protesto desta quarta coincidiu greve funcionários ferrovias suburbanas longa distância francesas provocou atrasos trens todo país CRÍTICAS reforma trabalhista irritou movimentos sociais especialmente porque sugerida Partido Socialista François Hollande anos havia conseguido aprovar jornada trabalho horas antecessor Hollande conservador Nicolas Sarkozy havia defendido aumento jornada levou proposta adiante devido pressão sindicatos franceses ministra Trabalho Miriam elKhomri defendeu lei avanço disse sindicatos ouvidos primeiroministro Manuel Valls afirmou proposta retirada embora diálogo continue intenção governo enviar medida Parlamento nesta quarta resistência movimentos sindicais dentro Partido Socialista atrasaram tramitação</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Google decidiu voltar atrás decisão proibir pornografia plataforma blogs Blogger receber muitas críticas blogueiros alguns quais donos páginas década conteúdo explícito ainda poderá ser postado meio ferramenta desde blog marcado adulto Jessica Pelegio gerente suporte produtos sociais companhia diz empresa recebeu muitas mensagens sobre proibição especialmente sobre obrigatoriedade blogueiros apagarem imagens eróticas modo retroativo desde início página forma sofrerem penalidades sites removidos marcados privados disponíveis apenas donos pessoas quais compartilham conteúdo aparecer buscas reclamaçes sobre impacto negativo indivíduos postam conteúdo sexual explícito expressar identidades disse Pelegio companhia poderia ver saída massa usuários plataformas Tumblr decidiu recuar Google havia alterado termos serviço Blogger impedir páginas exibiam conteúdo pornográfico gerassem dinheiro donos ficou proibido exibir anúncios nessas páginas objetivo impedir criação blogs praticamente repositórios conteúdo explícito geravam tráfego outros sites pornôs</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Convergente discussão acerca bloqueio Whatsapp texto relatório final aprovado CPI Crimes Cibernéticos nesta quartafeira tenta blindar aplicativo mensagens instantâneas última hora adicionado termo veda bloqueio aplicativos mensagens pessoais dois projetos lei alteram Marco Civil Internet todo encaminhados seis projetos lei CPI versam sobre ampliação definição invasão computadores aumento rigor lei destinação Fistel Fundo Fiscalização Telecomunicaçes órgãos Polícia Judiciária sobre mudanças Marco Civil relatório aprovado Agora projetos lei presentes relatório encaminhados comisses Câmara projeto lei prevê bloqueio aplicaçes pontos maior discussão Comissão Originalmente permitia medida judicial operadoras internet bloqueassem acesso aplicativo site utilizado práticas criminosas texto final ficou delimitado aplicaçes podem ser bloqueadas apenas hospedadas Brasil representação país dedicadas prática ilícita pena mínima crime sendo cometido dois Segundo relatores projetos complementa Marco Civil Internet prevê apenas retirada ar aplicaçes internet entanto especifica dá processo sites aplicativos hospedagem representação país texto aprovado CPI cria possibilidade juízes determinem operadoras façam bloqueio sessão terça deputados criticaram texto afirmaram redação banalizaria bloqueio aplicativo Apenas após críticas parágrafo blindando Whatsapp adicionado debate esquentou CPI após aplicativo ser bloqueado segundafeira medida juiz Marcel Montalvão comarca Lagarto terça entanto desembargador Ricardo Múcio Santana Abreu Lima Tribunal Justiça Sergipe revogou bloqueio texto aprovado atinge sites piratas disponibilizam listas BitTorrents arquivos mídia permitem usuários compartilhar vídeos músicas ilegais transmissão mídia Além disso relatores esperam possa impedir acesso sites contrabando tráfico drogas outro projeto lei altera Marco Civil CPI tenta permitir remoção bloqueio conteúdo meio ordens judiciais casos previstos nesse projeto baseia pena mínima anos crime praticado Segundo deputado Alessandro Molon RedeRJ votou contra relatório mudanças texto projetos lei suficientes garantir liberdade usuários rede principal crítica relator Marco Civil Internet previses retirada conteúdos meio simples decises judiciais permite chilling effect efeito resfriamento Retirase conteúdo judiciário decida sobre assunto enquanto conteúdo volta matase assunto diz Molon subrelator Sandro Alex PPSPR afirma Molon faz interpretação errada matéria deputado explica retirada texto possibilidade bloqueio remoção crimes pena menor dois anos retirando previsão crimes contra honra Retiramos acharem tentando blindar políticos Além disso aprovação lei apenas encaminhamento discussão diversas comisses afirma Alex</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  category_nro\n",
              "0  pouco ano Vinicius Lanza encontrou reação choro prova resultou decepção Então anos isolouse vestiário mergulhou desolação profunda enquanto lágrimas corriam rosto míseros cinco centésimos Jogos Rio dentro próprio Estádio Aquático Olímpico poucos meses sediaria megaevento esportivo exemplo vida natação repleta viradas partir desta terça Lanza chance promover Trezentos setenta sete dias após frustração seletiva olímpica chega Troféu Maria Lenk primeiro grande evento natação nacional ciclo melhor tempo entrada m borboleta eliminatória final nesta terça torneio Parque Aquático Maria Lenk dentro Parque Olímpico classificatório Mundial Budapeste julho vai marcar passagem bastão geraçesThiago Pereira exemplo aposentouse abril enquanto país vê surgir nomes Lanza outros ter ido Jogos bom manter fogo brigar vaga final medalha Tóquio diz mineiro hoje anos representa Minas Tênis Clube Medalha prata Campeonato Mundial júnior Cingapura m borboleta Lanza adotou EUA base início Estabeleceuse Bloomington Estado Indiana onde passou nadar universidade local estudar veterinária instituição passou ser orientado Ray Looze técnico integrou seleção norteamericana Rio guru Lilly King Cody Miller Blake Pieroni todos medalhistas Jogos Nesta temporada nadador brasileiro eleito capitão time universitário Ray disse Vini queria Olimpíada agora olhar pra frente contou nadador vaga Budapeste deve corroborar técnico disse Perder Olimpíada cinco centésimos ainda machuca fez manter foco maior mudança atitude resumiu Luiz Altamir viveu experiência diferente Conseguiu classificação Jogos Rio provas m livre revezamento x m livre passou primeira fase ambas nadador reconhece aprendizado pode ser interessante rumo Olimpíada Tóquio objetivo agora neste ciclo tentar ficar melhores mundo preciso treinar bastante Natural Roraima transferiu Flamengo Pinheiros nesta temporada clube paulistano divide raia Gabriel Santos Jogos Rio nadou revezamento x m livre Pedro Cardona perdeu Olimpíada pouco ficou terceiro m peito boa marca Pinheiros readquiriu Cesar Cielo nadador vitorioso história país mudou filosofia Dispensou medalhes olímpicos Bruno Fratus João Lucca apostou nova safra Percebemos hora mudar mentalidade afirmou técnico principal clube Alberto Pinto Silva Outros bons valores estarão Troféu Maria Lenk Brandonn Almeida nadou m medley m livre Rio deve mudar EUA competição fundista Guilherme Costa abril bateu recorde sulamericano m livre espera estabelecerse expoentes geração confiante Maria Lenk conseguir melhorar tempo vou Mundial disse CRISE coisa abala confiança promessas situação turbulenta passa CBDA Confederação Brasileira Desportos Aquáticos Acusados corrupção quatro dirigentes presos meio entidade perdeu patrocínio Bradesco viu despencar aporte feito Correios investimento vai diminuir bastante vai ser dificuldade grande nova geração busca novas competiçes lá afirmou Luiz Altamir nadador disse espera nova gestão transparência melhor melhor maneira ter credibilidade novo mudar tudo Pensamento estratégia busca novos patrocinadores Renovar palavra certa complementou Altamir Vinícius Lanza acrise abateu sobre confederação triste vai afetar geração Sobre dirigentes presos afirmou Justiça decide eventos Troféu Maria Lenk TERÇAFEIRA Eliminatórias h finais h m borboleta Feminino Masculino m livre F M m peito F M x m livre F M QUARTAFEIRA Eliminatórias h finais h m costas F M m medley F M m livre F m livre M QUINTAFEIRA Eliminatórias h finais h m livre F M m peito FeM m costas F M m borboleta F M SEXTAFEIRA Eliminatórias h finais h m medley F M m livre F M m costas F M m borboleta F M x m livre F M SÁBADO Eliminatórias h finais h m peito F M m livre F M m livre F m livre M x m medley F M             2\n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  situação financeira Paulo apesar restriçes despesas ligeiro aumento arrecadação registrado recentemente delicada secretário Fazenda Luis Arrobas Martins diz arrecadação ICM Imposto sobre Circulação Mercadorias primeiro semestre deveria ser NCr milhes R bilhes ficou NCr milhes R bilhes queda Além distanciar previsão orçamentária governo Estado reduziu desejava orçamentos Secretarias Educação Segurança Pública             6\n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Dezenas milhares pessoas participaram nesta quartafeira França dia protestos convocados sindicalistas estudantes contra reforma lei trabalhista país impulsionada governo ato resposta intenção presidente François Hollande permitir empresas mudar jornada trabalho funcionários além horas semanais determinadas lei remuneração adicional novo modelo trabalhadores poderão trabalhar horas diárias horas semanais seguir pactos sindicatos troca funcionários passarão receber folgas extras fazem parte reforma medidas reduzir regras demisses trabalho remoto noturno medida defendida governo forma reduzir taxa desemprego França manifestaçes reuniram trabalhadores desempregados estudantes responderam chamado sindicatos movimento estudantil protestaram cidades francesas Paris número manifestantes chegou mil protesto desta quarta coincidiu greve funcionários ferrovias suburbanas longa distância francesas provocou atrasos trens todo país CRÍTICAS reforma trabalhista irritou movimentos sociais especialmente porque sugerida Partido Socialista François Hollande anos havia conseguido aprovar jornada trabalho horas antecessor Hollande conservador Nicolas Sarkozy havia defendido aumento jornada levou proposta adiante devido pressão sindicatos franceses ministra Trabalho Miriam elKhomri defendeu lei avanço disse sindicatos ouvidos primeiroministro Manuel Valls afirmou proposta retirada embora diálogo continue intenção governo enviar medida Parlamento nesta quarta resistência movimentos sindicais dentro Partido Socialista atrasaram tramitação             3\n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Google decidiu voltar atrás decisão proibir pornografia plataforma blogs Blogger receber muitas críticas blogueiros alguns quais donos páginas década conteúdo explícito ainda poderá ser postado meio ferramenta desde blog marcado adulto Jessica Pelegio gerente suporte produtos sociais companhia diz empresa recebeu muitas mensagens sobre proibição especialmente sobre obrigatoriedade blogueiros apagarem imagens eróticas modo retroativo desde início página forma sofrerem penalidades sites removidos marcados privados disponíveis apenas donos pessoas quais compartilham conteúdo aparecer buscas reclamaçes sobre impacto negativo indivíduos postam conteúdo sexual explícito expressar identidades disse Pelegio companhia poderia ver saída massa usuários plataformas Tumblr decidiu recuar Google havia alterado termos serviço Blogger impedir páginas exibiam conteúdo pornográfico gerassem dinheiro donos ficou proibido exibir anúncios nessas páginas objetivo impedir criação blogs praticamente repositórios conteúdo explícito geravam tráfego outros sites pornôs             6\n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Convergente discussão acerca bloqueio Whatsapp texto relatório final aprovado CPI Crimes Cibernéticos nesta quartafeira tenta blindar aplicativo mensagens instantâneas última hora adicionado termo veda bloqueio aplicativos mensagens pessoais dois projetos lei alteram Marco Civil Internet todo encaminhados seis projetos lei CPI versam sobre ampliação definição invasão computadores aumento rigor lei destinação Fistel Fundo Fiscalização Telecomunicaçes órgãos Polícia Judiciária sobre mudanças Marco Civil relatório aprovado Agora projetos lei presentes relatório encaminhados comisses Câmara projeto lei prevê bloqueio aplicaçes pontos maior discussão Comissão Originalmente permitia medida judicial operadoras internet bloqueassem acesso aplicativo site utilizado práticas criminosas texto final ficou delimitado aplicaçes podem ser bloqueadas apenas hospedadas Brasil representação país dedicadas prática ilícita pena mínima crime sendo cometido dois Segundo relatores projetos complementa Marco Civil Internet prevê apenas retirada ar aplicaçes internet entanto especifica dá processo sites aplicativos hospedagem representação país texto aprovado CPI cria possibilidade juízes determinem operadoras façam bloqueio sessão terça deputados criticaram texto afirmaram redação banalizaria bloqueio aplicativo Apenas após críticas parágrafo blindando Whatsapp adicionado debate esquentou CPI após aplicativo ser bloqueado segundafeira medida juiz Marcel Montalvão comarca Lagarto terça entanto desembargador Ricardo Múcio Santana Abreu Lima Tribunal Justiça Sergipe revogou bloqueio texto aprovado atinge sites piratas disponibilizam listas BitTorrents arquivos mídia permitem usuários compartilhar vídeos músicas ilegais transmissão mídia Além disso relatores esperam possa impedir acesso sites contrabando tráfico drogas outro projeto lei altera Marco Civil CPI tenta permitir remoção bloqueio conteúdo meio ordens judiciais casos previstos nesse projeto baseia pena mínima anos crime praticado Segundo deputado Alessandro Molon RedeRJ votou contra relatório mudanças texto projetos lei suficientes garantir liberdade usuários rede principal crítica relator Marco Civil Internet previses retirada conteúdos meio simples decises judiciais permite chilling effect efeito resfriamento Retirase conteúdo judiciário decida sobre assunto enquanto conteúdo volta matase assunto diz Molon subrelator Sandro Alex PPSPR afirma Molon faz interpretação errada matéria deputado explica retirada texto possibilidade bloqueio remoção crimes pena menor dois anos retirando previsão crimes contra honra Retiramos acharem tentando blindar políticos Além disso aprovação lei apenas encaminhamento discussão diversas comisses afirma Alex             6"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxhXdXAcG4YR",
        "outputId": "0bdb7cb7-8fde-4be0-c06b-ee66d920db4c"
      },
      "source": [
        "dfPreProc_Teste = PreProcessamentoParalelo(dfteste,mp.cpu_count())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUCZM0Jaq9Zc"
      },
      "source": [
        "CRIANDO WORD2VEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke4TVkvuIGyu"
      },
      "source": [
        "''' transformar o texto das noticias em uma lista de n-grams. Usaremos uni-gramas, bi-gramas e tri-gramas\n",
        "  algoritmo obtido do artigo https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794\n",
        "'''\n",
        "lst_corpus, bigrams_detector, trigrams_detector =  obtemListasn_grams(dfPreProc['text'])\n",
        "lst_corpus_teste, bigrams_teste, trigrams_teste =  obtemListasn_grams(dfPreProc['text'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cILv-OgJGQZ"
      },
      "source": [
        "#lst_corpus = trigrams_detector\n",
        "#lst_corpus_teste = trigrams_test"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_e8GgLC9WsW",
        "outputId": "7f60f641-810d-427b-bf42-8e7393a51469"
      },
      "source": [
        "tamanho = [len(i) for i in lst_corpus]\n",
        "print('menor:', min(tamanho),'media:', np.round(np.mean(tamanho),1), 'mediana:',np.median(tamanho), 'maximo:',max(tamanho) )"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "menor: 1 media: 253.7 mediana: 217.0 maximo: 5235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWQavIebD3-9",
        "outputId": "a744c61f-10e8-4d84-f8cc-caac435e527b"
      },
      "source": [
        "[[i,t] for i,t in enumerate(tamanho)][0:10]\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 547],\n",
              " [1, 51],\n",
              " [2, 178],\n",
              " [3, 129],\n",
              " [4, 337],\n",
              " [5, 28],\n",
              " [6, 250],\n",
              " [7, 328],\n",
              " [8, 292],\n",
              " [9, 162]]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKBi2E2pq4bV",
        "outputId": "3a4e991b-707f-4ca6-964f-0f0a8c021ee4"
      },
      "source": [
        "print(list(bigrams_detector.phrasegrams.keys())[0:10])\n",
        "print(list(trigrams_detector.phrasegrams.keys())[0:10])\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(b'est\\xc3\\xa1di', b'aqu\\xc3\\xa1'), (b'dest', b'ter\\xc3\\xa7'), (b'trof\\xc3\\xa9u', b'mar'), (b'mar', b'lenk'), (b'm', b'borbolet'), (b'nest', b'ter\\xc3\\xa7'), (b'parqu', b'aqu\\xc3\\xa1'), (b'parqu', b'ol\\xc3\\xadmp'), (b'ter', b'ido'), (b't\\xc3\\xaanil', b'club')]\n",
            "[(b'jog', b'rio'), (b'pouc', b'mes'), (b'dest', b'ter\\xc3\\xa7'), (b'part', b'dest ter\\xc3\\xa7'), (b'part dest', b'ter\\xc3\\xa7'), (b'sele', b'ol\\xc3\\xadmp'), (b'trof\\xc3\\xa9u', b'mar'), (b'trof\\xc3\\xa9u', b'mar lenk'), (b'trof\\xc3\\xa9u mar', b'lenk'), (b'm', b'borbolet')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOUogTkBq4eb"
      },
      "source": [
        "## fit w2v\n",
        "nlp = gensim.models.word2vec.Word2Vec(sentences=lst_corpus, size=300,   \n",
        "            window=8, min_count=1, sg=1, iter=30)\n",
        "nlp.save('./classica_resp/nlp_w2vec.sav')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exgh8IU0q4h7",
        "outputId": "2b323a6d-a050-4119-d2d6-93bde5b4ad67"
      },
      "source": [
        "# obter o vetor da palavra primavera\n",
        "word = 'primavera'\n",
        "nlp.wv.__getitem__(word).shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgiehQ0t74hJ"
      },
      "source": [
        "nlp = gensim.models.word2vec.Word2Vec.load('./classica_resp/nlp_w2vec.sav')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeR3sMdf788j"
      },
      "source": [
        "# Rede Neural\n",
        "\n",
        "* Primeiro, transforme o corpus em sequências preenchidas de ids de palavras para obter uma matriz de recursos.\n",
        "* Em seguida, crie uma matriz de incorporação de forma que o vetor da palavra com id N esteja localizado na enésima linha.\n",
        "* Finalmente, construa uma rede neural com uma camada de incorporação que pesa cada palavra nas sequências com o vetor correspondente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmHbNmXwJ5v4"
      },
      "source": [
        "#tokenizar: Transformar o corpus pré-processado (lista de n-gramas: lst_corpous) em uma lista de sequência \n",
        "max_length=128\n",
        "X_train, lst_text2seq, dic_vocabulary = tokenizar(lst_corpus, max_length)\n",
        "X_teste = tokenizar(lst_corpus, max_length)[0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SWKJpSP0nOW"
      },
      "source": [
        "y_train  = dfPreProc['category_nro']\n",
        "y_teste = dfPreProc_Teste['category_nro']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEl_e4o074mK",
        "outputId": "6583c81e-9579-46fb-cc00-735c21b1b95e"
      },
      "source": [
        "len(dic_vocabulary.keys())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74955"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8akq0vNBEjN",
        "outputId": "40a05b30-6c91-4d4e-c053-67d70a4b1b5c"
      },
      "source": [
        "lst_text2seq[0][0:15]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[134,\n",
              " 1,\n",
              " 4458,\n",
              " 18415,\n",
              " 119,\n",
              " 1236,\n",
              " 1256,\n",
              " 105,\n",
              " 139,\n",
              " 5927,\n",
              " 184,\n",
              " 1,\n",
              " 40026,\n",
              " 4915,\n",
              " 3107]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnmpCfIyCOoK",
        "outputId": "a564b49f-dd23-4bf8-886a-542637c4a34f"
      },
      "source": [
        "print(X_train[0], '\\n \\n', X_train[1])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  134     1  4458 18415   119  1236  1256   105   139  5927   184     1\n",
            " 40026  4915  3107 10286  1255   219  4039   455  1909 25586   294  2858\n",
            "    42   130   375   496  1206  3980   749   134   163  2619 14997  1943\n",
            "   160    97  2663  3790   403    12    67   524 18415   810   941 25587\n",
            " 11565   150    14    41  2372  2598   749    45  3660   263  9742    23\n",
            "    54   257  2663    93  1140    60    62   129  1180  5527  3108   121\n",
            "    16   524  1327  1598  3980   263  9742   375  1598   749 12477    46\n",
            "  5928   689    43   122    15   478 40027  1365   160 22350   614   219\n",
            "    24  1021   793   220 18415     6    26  4739    42   396   372  1725\n",
            "  1274   330   121  1362  2742     8   710    84     1   259   710  2880\n",
            "   504  1362  1844  1059    46  2321  4701  1180] \n",
            " \n",
            " [  352   237    31   353  2394  1290   288   140  1330   205   431  3225\n",
            "   238  1080  1970 14998  2709     8  1330  4637   896     9  1428  2256\n",
            "    23  1045    27     4 18416    47    29   212    35 18416    47    29\n",
            "   212   331    80  5989   954  2761    18    13   489   875  1090   238\n",
            "    89   312    40     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss15PqDUGOgI"
      },
      "source": [
        "'''criar uma matriz embedding para usar como peso na rede neural do classificador.\n",
        "   cada palavra no dicionário das noticias recebá o vetor do word2vec. '''\n",
        "\n",
        "## inicia uma matrix zerada de shape tamanho do vocabulário x tamanho do vetor\n",
        "embeddings = np.zeros((len(dic_vocabulary)+1, 300))\n",
        "for word,idx in dic_vocabulary.items():\n",
        "    ## atualiza a linha da matriz com o vetor do word2vec nlp.\n",
        "    try:\n",
        "        embeddings[idx] =  nlp.wv.__getitem__(word)\n",
        "    ## se a palavra não estiver em nlp, o vetor de pesos desta palavra ficará zerado.\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCNYpbVjGO1X",
        "outputId": "27dd3b1f-702e-44f5-df37-b97efacef484"
      },
      "source": [
        "''' criar a rede neural para o classificador que terá as seguintes camadas:\n",
        "  * embedding - obtem as sequências (noticias tokenizadas em X_train) como entrada e o \n",
        "    vetor de palavras que compõem cada noticia (embeddings) como pesos.\n",
        "  * simple Attention layer - proposto por Bahdanau, Cho e Bengio, 2014 e também em quase todos os modelos apresentados no estudo bibliográfico - \n",
        "    permite entender qual parte do texto é realmente relevante. Captura os pesos de cada instância e ajuda a construir um explicador, sendo que \n",
        "    não é necessário para as previsões, apenas para a explicabilidade.\n",
        "  * Duas camdas de LSTM Bidirecional para modelar a ordem das palaras em uma sequencia em ambas as direções.\n",
        "  * Duas camadas densas finais que irão prever a probabilidade de cada categoria de notícias.\n",
        "'''\n",
        "\n",
        "## code attention layer\n",
        "def attention_layer(inputs, neurons):\n",
        "    x = layers.Permute((2,1))(inputs) #permuta a forma (shape) de entrada usando o padrão (2,1)\n",
        "    x = layers.Dense(neurons, activation=\"softmax\")(x) #executa a função de ativação softmax na matrix de entrada que foi transformada em x e nos neurons (pesos). \n",
        "                                                       #output = activation(dot(input, kernel) + bias) input=x, kernel=neurons (pesos)\n",
        "    x = layers.Permute((2,1), name=\"attention\")(x) \n",
        "    x = layers.multiply([inputs, x]) \n",
        "    return x\n",
        "\n",
        "## input\n",
        "x_in = layers.Input(shape=(max_length,))\n",
        "## embedding\n",
        "x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
        "                     output_dim=embeddings.shape[1], \n",
        "                     weights=[embeddings],\n",
        "                     input_length=max_length, trainable=False)(x_in)\n",
        "## apply attention\n",
        "x = attention_layer(x, neurons=max_length)\n",
        "## 2 layers of bidirectional lstm\n",
        "x = layers.Bidirectional(layers.LSTM(units=max_length, dropout=0.2, \n",
        "                         return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(units=max_length, dropout=0.2))(x)\n",
        "## final dense layers\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "y_out = layers.Dense(10, activation='softmax')(x)\n",
        "## compile\n",
        "model = models.Model(x_in, y_out)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "   \n",
        "  \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 128, 300)     22486800    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 300, 128)     0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 300, 128)     16512       permute_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "attention (Permute)             (None, 128, 300)     0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 128, 300)     0           embedding_2[0][0]                \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 128, 256)     439296      multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 256)          394240      bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 64)           16448       bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 10)           650         dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,353,946\n",
            "Trainable params: 867,146\n",
            "Non-trainable params: 22,486,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLZIGvt6zw-A"
      },
      "source": [
        "'''treinando o modelo '''\n",
        "## encode y\n",
        "dic_y_mapping = {n:label for n,label in \n",
        "                 enumerate(np.unique(y_train))}\n",
        "inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n",
        "y_train = np.array([inverse_dic[y] for y in y_train])\n",
        "## train\n",
        "training = model.fit(x=X_train, y=y_train, batch_size=256, \n",
        "                     epochs=10, shuffle=True, verbose=0, \n",
        "                     validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7XAy9G102n8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ533RsIGhJx"
      },
      "source": [
        "#imprimeMetricas(y_pred_nb, y_teste,'./classica_resp/nb_v1.scr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "728qr3F2GhM-"
      },
      "source": [
        "classes = np.unique(y_teste)\n",
        "y_test_array = pd.get_dummies(y_teste, drop_first=False).values\n",
        "fig, ax = plt.subplots(figsize=(12,8),nrows=1, ncols=2)\n",
        "## Plot roc\n",
        "for i in range(len(classes)):\n",
        "    fpr, tpr, thresholds = roc_curve(y_test_array[:,i],  \n",
        "                           predicted_prob[:,i])\n",
        "    ax[0].plot(fpr, tpr, lw=3, \n",
        "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
        "                              auc(fpr, tpr))\n",
        "               )\n",
        "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
        "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
        "          xlabel='False Positive Rate', \n",
        "          ylabel=\"True Positive Rate (Recall)\", \n",
        "          title=\"Receiver operating characteristic\")\n",
        "ax[0].legend(loc=\"lower right\")\n",
        "ax[0].grid(True)\n",
        "\n",
        "## Plot precision-recall curve\n",
        "for i in range(len(classes)):\n",
        "    precision, recall, thresholds = precision_recall_curve(\n",
        "                 y_test_array[:,i], predicted_prob[:,i])\n",
        "    ax[1].plot(recall, precision, lw=3, \n",
        "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
        "                                  auc(recall, precision))\n",
        "              )\n",
        "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
        "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
        "ax[1].legend(loc=\"best\")\n",
        "ax[1].grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk32mwzfGhQP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55ZyIiT0GhTQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10xz4F2oGhWf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHx4qc9mmcqK"
      },
      "source": [
        "KNN"
      ]
    }
  ]
}