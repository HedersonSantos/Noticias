{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clusterizacaoNoticias",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbi8KV1vKit733gzVoRC8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HedersonSantos/Noticias/blob/main/clusterizacaoNoticias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ntCB_ZoYIR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk, re\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report, accuracy_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATJaqnNUqr_L"
      },
      "source": [
        "# Obtendo dataset de noticias tratadas em preProcessamento_noticias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnmIRw0WowrK",
        "outputId": "6b6f82fd-0e2e-4d6b-8df3-1b2c014a0d1a"
      },
      "source": [
        "!rm news.*\n",
        "!wget https://raw.githubusercontent.com/HedersonSantos/Noticias/main/news.zip\n",
        "!unzip news.zip\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'news.*': No such file or directory\n",
            "--2021-06-19 14:27:18--  https://raw.githubusercontent.com/HedersonSantos/Noticias/main/news.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11333903 (11M) [application/zip]\n",
            "Saving to: ‘news.zip’\n",
            "\n",
            "news.zip            100%[===================>]  10.81M  40.4MB/s    in 0.3s    \n",
            "\n",
            "2021-06-19 14:27:18 (40.4 MB/s) - ‘news.zip’ saved [11333903/11333903]\n",
            "\n",
            "Archive:  news.zip\n",
            "  inflating: news.csv                \n",
            "news.csv  news.zip  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWX1z5Ntq-Ec"
      },
      "source": [
        "# Funções para processamento de Linguagem Natural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmvLl_wTrFR9"
      },
      "source": [
        "def download_pt_stopWords():\n",
        "  '''download das stopwords '''\n",
        "        nltk.download('stopwords')\n",
        "        \n",
        "def removeStopWords(self, texto, excluirWords:list=None):\n",
        "   '''remove as stopwords do texto. Novas stopwords podem ser adicionadas através da lista excluirWords'''\n",
        "    naoQueridas = nltk.corpus.stopwords.words('portuguese')\n",
        "    naoQueridas.extend(excluirWords)\n",
        "    naoQueridas = list(set(naoQueridas))\n",
        "    palavras = [i for i in texto.split() if not i.lower() in naoQueridas]\n",
        "    return (\" \".join(palavras))\n",
        "def aplicaStemming(self, texto):\n",
        "    ''' obtém o radical das palavras do vocabulário'''\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    palavras = []\n",
        "    for w in texto.split():\n",
        "        palavras.append(stemmer.stem(w))\n",
        "    return (\" \".join(palavras))\n",
        "\n",
        "def removeCaracteresNaoDesejados(self,texto):\n",
        "    textoLimpo = re.sub(r\"http\\S+\", \"\", texto)\n",
        "    textoLimpo = re.sub(r\"www\\..+\\..+\", \"\", texto)\n",
        "    textoLimpo = re.sub(r\"[^a-zA-ZáÁéÉíÍóÓúÚãÃàÀôâÂêÊôÔçÇ!,:.; ]\", \"\", texto)\n",
        "    \n",
        "    return textoLimpo\n",
        "\n",
        "def retornaVetorizacao(self,X,pct_min=1, pct_max=1, excluirSW:list=None):\n",
        "  ''' monta a matriz sparsa com o índice de vocabulário em cada texto. \n",
        "      Retorna a matriz sparsa e o vocabulário '''\n",
        "    count_vect = CountVectorizer(min_df=pct_min, max_df=pct_max, lowercase=True,stop_words=stopwords) \n",
        "    matriz_sparsa = count_vect.fit_transform(X)\n",
        "    vocabulario = count_vect.fit(X)\n",
        "    return [matriz_sparsa,count_vect]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}