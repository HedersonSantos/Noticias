{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTimbau_Testes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HedersonSantos/Noticias/blob/main/BERT/BERTimbau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKMj5WG6lxGP",
        "outputId": "5343582a-10f3-4dfb-e8c3-3ada7b305b27"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIlZbdsGo_vR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cff477c-1e0d-4b45-e699-d0ee07da055a"
      },
      "source": [
        "\n",
        "!pip install torch==1.8.1 torchvision==0.9.1 torchaudio==0.8.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: torchaudio==0.8. in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky7aWx6DyYU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99ee885-0664-4d46-f440-72baa11abff0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul  5 13:09:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hts6ewoYvUYn"
      },
      "source": [
        "# Libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Preliminaries\n",
        "\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "\n",
        "# Models\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from transformers import AutoTokenizer  # Or BertTokenizer\n",
        "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n",
        "from transformers import AutoModel  # or BertModel, for BERT without pretraining heads\n",
        "\n",
        "# Training\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPOdGbGitPHS"
      },
      "source": [
        "### Carregando tokens e vocabulário do BERTimbau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLcgDJZSpmfD",
        "outputId": "9d61bf80-4646-4281-9697-aefd7cf39abc"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joJqFofvtKcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1043828-00a6-45d3-fa90-a4c79613b48e"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='neuralmind/bert-base-portuguese-cased', vocab_size=29794, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjyelXiX0SwM",
        "outputId": "890f70bd-576a-4477-f62d-27d26bfd997e"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZOL2o_ltyzz"
      },
      "source": [
        "### Preparando DataSet\n",
        "https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFtrA_dtunW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5510ae12-f004-4ca4-ab81-70557b6f0368"
      },
      "source": [
        "!rm *.csv\n",
        "!!wget https://raw.githubusercontent.com/HedersonSantos/Noticias/main/train.csv\n",
        "!wget https://raw.githubusercontent.com/HedersonSantos/Noticias/main/valid.csv\n",
        "!wget https://raw.githubusercontent.com/HedersonSantos/Noticias/main/test.csv\n",
        "!wget https://raw.githubusercontent.com/HedersonSantos/Noticias/main/miscelanea.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 19:10:50--  https://raw.githubusercontent.com/HedersonSantos/Noticias/main/valid.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 766616 (749K) [text/plain]\n",
            "Saving to: ‘valid.csv’\n",
            "\n",
            "\rvalid.csv             0%[                    ]       0  --.-KB/s               \rvalid.csv           100%[===================>] 748.65K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-06-05 19:10:51 (17.9 MB/s) - ‘valid.csv’ saved [766616/766616]\n",
            "\n",
            "--2021-06-05 19:10:51--  https://raw.githubusercontent.com/HedersonSantos/Noticias/main/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 734032 (717K) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>] 716.83K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-06-05 19:10:51 (24.0 MB/s) - ‘test.csv’ saved [734032/734032]\n",
            "\n",
            "--2021-06-05 19:10:51--  https://raw.githubusercontent.com/HedersonSantos/Noticias/main/miscelanea.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2269798 (2.2M) [text/plain]\n",
            "Saving to: ‘miscelanea.csv’\n",
            "\n",
            "miscelanea.csv      100%[===================>]   2.16M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-06-05 19:10:51 (47.3 MB/s) - ‘miscelanea.csv’ saved [2269798/2269798]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV8T4nMYXqdR",
        "outputId": "c6c473b5-5427-4f75-f9e6-e0a49d76bad5"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sjrTvfBLGCL"
      },
      "source": [
        "source_folder = '/content' #'/content'\n",
        "destination_folder = '/content' #'/content'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90WJxOxcxgAQ",
        "outputId": "1f22d3d4-288a-4641-954b-b861f57f55ae"
      },
      "source": [
        "!ls /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "miscelanea.csv\tsample_data  test.csv  train.csv  valid.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyoK7ac8t4HF"
      },
      "source": [
        "#https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613\n",
        "#Model parameter\n",
        "MAX_SEQ_LEN = 128 #limita os artigos em 128 tokens. Bert é limitado em 512 tokens por texto (checar isto e aplicar limpeza nos textos).\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
        "bs = 16\n",
        "\n",
        "# Fields - use_vocab=False  e tokenizer.encode permite que utilizemos os tokens do BERTimbau.\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
        "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
        "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
        "fields = [('text', text_field),('label', label_field)]\n",
        "\n",
        "# TabularDataset\n",
        "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='valid.csv',\n",
        "                                           test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
        "\n",
        "# Iterators\n",
        "\n",
        "train_iter = BucketIterator(train, batch_size=bs, sort_key=lambda x: len(x.text),\n",
        "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
        "valid_iter = BucketIterator(valid, batch_size=bs, sort_key=lambda x: len(x.text),\n",
        "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
        "test_iter = Iterator(test, batch_size=bs, device=device, train=False, shuffle=False, sort=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcTHSXSluKkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1f4385-73ec-4827-ffd0-4771dd093afb"
      },
      "source": [
        "print(vars(train[0]))\n",
        "print(vars(valid[0]))\n",
        "print(vars(test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [101, 13647, 240, 3426, 6071, 13647, 240, 3426, 6071, 1833, 210, 9930, 6276, 5347, 125, 257, 109, 10081, 192, 5772, 125, 5506, 320, 7007, 9058, 11465, 22307, 2506, 119, 223, 22283, 119, 14979, 22302, 113, 11388, 114, 118, 977, 22296, 12763, 1704, 2030, 4639, 5485, 145, 117, 420, 2859, 123, 187, 21557, 113, 4045, 8966, 20345, 298, 13232, 114, 122, 123, 359, 22328, 22321, 113, 2674, 3479, 298, 13232, 114, 4882, 123, 6191, 13030, 12001, 712, 16271, 180, 3159, 117, 8487, 10159, 124, 113, 15166, 118, 14215, 114, 117, 122, 171, 6225, 117, 7697, 19734, 113, 10836, 22311, 118, 13293, 114, 117, 230, 981, 125, 8658, 179, 17833, 228, 173, 2154, 119, 177, 9358, 180, 2052, 1112, 22026, 404, 10784, 366, 11401, 4639, 5485, 145, 22354, 117, 9183, 221, 123, 4669, 100, 14258, 113, 2633, 119, 223, 22283, 119, 14979, 22302, 114, 117, 2810, 13460, 240, 222, 5291, 119, 2195, 4428, 180, 187, 21557, 117, 1112, 146, 5291, 171, 644, 2633, 346, 5707, 22303, 3680, 125, 4768, 179, 5963, 22287, 11621, 737, 22354, 119, 177, 16736, 4479, 567, 19350, 1676, 11401, 4639, 5485, 145, 4328, 2506, 19284, 832, 119, 1431, 4687, 253, 221, 179, 146, 9930, 6276, 5347, 781, 185, 123, 370, 146, 2261, 125, 257, 109, 10081, 122, 1547, 12659, 1139, 3072, 684, 259, 3997, 11720, 180, 9196, 769, 151, 119, 5394, 2009, 10865, 286, 954, 18946, 122, 179, 2810, 4847, 320, 4855, 253, 146, 22128, 125, 5772, 125, 5506, 320, 7007, 119, 1629, 125, 187, 21557, 122, 359, 22328, 22321, 117, 4366, 670, 180, 6528, 123, 10484, 22293, 113, 10385, 1580, 298, 13232, 2225, 2030, 13226, 8521, 2841, 122, 13226, 8521, 1516, 22281, 5600, 6355, 114, 117, 146, 15769, 22321, 113, 8452, 298, 13232, 2225, 2030, 834, 2690, 114, 122, 260, 21880, 771, 6612, 122, 10875, 4673, 2619, 22280, 119, 8159, 21725, 117, 1640, 180, 187, 21557, 117, 3415, 179, 1112, 146, 2049, 698, 3891, 11062, 117, 146, 5155, 125, 1069, 8231, 117, 259, 8731, 298, 6571, 117, 171, 5721, 13403, 228, 122, 146, 9930, 6276, 5347, 262, 10939, 119, 1431, 739, 14941, 22354, 119, 2195, 368, 117, 123, 6287, 171, 2261, 171, 9930, 253, 1112, 222, 5846, 22354, 119, 1112, 1645, 222, 5846, 744, 636, 253, 146, 1161, 20354, 716, 157, 370, 10939, 146, 1189, 125, 1101, 179, 1146, 3859, 1966, 9930, 117, 1790, 21229, 1050, 221, 4365, 744, 325, 4594, 7282, 22287, 11062, 122, 179, 146, 806, 19789, 22279, 230, 5572, 18254, 1979, 22354, 119, 9058, 11465, 22307, 10508, 122, 118, 223, 215, 221, 9058, 11465, 22307, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 11044, 16210, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 11044, 16210, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 240, 9058, 11465, 22307, 2174, 2215, 215, 296, 13647, 240, 3426, 6071, 20022, 131, 195, 173, 18376, 22290, 2561, 8454, 22284, 197, 959, 10508, 221, 325, 125, 230, 2760, 117, 21333, 823, 259, 14441, 22281, 240, 1666, 22282, 225, 966, 119, 14979, 22302, 100, 4859, 259, 3015, 9058, 11465, 22307, 119, 102], 'label': '7'}\n",
            "{'text': [101, 8759, 15906, 634, 8759, 15906, 634, 1715, 359, 7918, 117, 202, 1007, 125, 1455, 275, 120, 16899, 120, 14979, 22302, 16720, 22296, 554, 19900, 249, 11130, 180, 2967, 978, 146, 8846, 125, 176, 2357, 125, 2200, 119, 959, 1257, 117, 176, 3171, 125, 651, 170, 123, 1288, 625, 744, 978, 1433, 481, 119, 14459, 173, 222, 3515, 202, 8283, 117, 582, 1767, 240, 1685, 481, 119, 14459, 240, 1210, 736, 4021, 170, 146, 9518, 125, 19900, 249, 7140, 367, 1669, 119, 1645, 262, 222, 8431, 221, 333, 8892, 22325, 125, 7749, 1528, 179, 9972, 22300, 173, 222, 998, 179, 3171, 327, 1069, 119, 177, 1018, 4438, 682, 2112, 125, 4696, 117, 368, 176, 7114, 203, 744, 325, 1676, 4026, 127, 626, 585, 119, 231, 596, 346, 221, 256, 122, 146, 8846, 125, 5152, 173, 222, 2504, 739, 1993, 495, 1078, 576, 2892, 119, 231, 2200, 117, 202, 1325, 117, 2364, 5127, 180, 327, 3827, 119, 192, 170, 123, 14516, 298, 682, 117, 368, 12351, 9755, 20509, 202, 21211, 10326, 117, 582, 12044, 748, 170, 15605, 3507, 4102, 458, 122, 770, 6921, 205, 117, 245, 6271, 125, 9499, 119, 107, 177, 13588, 124, 5971, 785, 119, 14333, 15854, 214, 22003, 653, 202, 21211, 10326, 119, 3396, 5057, 2183, 125, 3822, 122, 6814, 22283, 222, 2934, 179, 12044, 748, 122, 3171, 7122, 1069, 119, 1807, 348, 170, 123, 4273, 7700, 229, 4014, 117, 170, 6970, 125, 1394, 4516, 122, 179, 346, 16616, 692, 119, 1643, 2389, 9193, 117, 260, 4739, 3290, 12044, 2208, 119, 3479, 13608, 348, 7343, 2934, 119, 6582, 1351, 123, 5698, 7122, 1069, 107, 117, 1996, 146, 11046, 22282, 320, 359, 7918, 9151, 119, 1431, 4733, 20502, 285, 240, 248, 192, 278, 257, 192, 267, 192, 113, 137, 2779, 514, 846, 185, 114, 231, 8846, 125, 333, 2357, 2200, 262, 11735, 8501, 119, 9755, 20509, 1367, 529, 5697, 125, 1037, 240, 8283, 117, 10345, 117, 8760, 122, 548, 240, 222, 2504, 180, 1975, 119, 787, 176, 3339, 3770, 423, 11468, 22288, 117, 173, 4155, 117, 449, 117, 123, 3295, 117, 253, 179, 2364, 2286, 5212, 171, 7171, 271, 21454, 119, 107, 20611, 170, 2169, 15482, 122, 3486, 10773, 179, 770, 4360, 3866, 222, 1342, 3420, 119, 4957, 289, 22283, 123, 1434, 8558, 125, 3478, 4810, 117, 449, 346, 495, 221, 9726, 119, 510, 4486, 506, 6738, 221, 1342, 1341, 117, 146, 2200, 346, 4750, 325, 4945, 125, 9726, 195, 3979, 128, 197, 122, 1642, 244, 12022, 221, 146, 1147, 6936, 119, 3396, 1684, 8766, 185, 22283, 366, 14175, 117, 125, 7505, 122, 662, 289, 22283, 123, 1434, 240, 1284, 2288, 119, 12603, 123, 2538, 117, 146, 2934, 5401, 3093, 2256, 22288, 119, 107, 6312, 3885, 9755, 20509, 262, 5945, 214, 179, 347, 3753, 346, 495, 202, 2200, 119, 3393, 1767, 6054, 625, 262, 6303, 221, 333, 8892, 22325, 125, 9972, 22300, 173, 222, 998, 119, 787, 21283, 202, 1586, 15494, 117, 449, 2471, 125, 4412, 682, 2112, 20369, 944, 259, 1564, 119, 1643, 13256, 146, 3495, 179, 3859, 151, 240, 644, 271, 3620, 117, 346, 17662, 924, 1176, 122, 9093, 146, 1774, 119, 107, 7846, 22288, 230, 13254, 4554, 4111, 179, 3804, 322, 125, 6384, 221, 1434, 222, 998, 119, 10304, 22290, 311, 18574, 122, 311, 17861, 119, 19687, 22305, 146, 3515, 122, 7282, 22283, 119, 20484, 978, 2160, 3418, 117, 3874, 117, 1203, 123, 1354, 125, 16341, 653, 119, 20564, 4435, 22279, 179, 11650, 173, 1434, 146, 998, 291, 3866, 5699, 214, 202, 1774, 119, 19687, 19623, 229, 10188, 122, 4789, 175, 22283, 2249, 495, 146, 13850, 22325, 119, 3362, 257, 109, 10081, 123, 17222, 122, 202, 1774, 16653, 230, 2565, 125, 5155, 125, 257, 109, 3055, 119, 13716, 4174, 244, 924, 1176, 117, 3283, 146, 998, 107, 117, 10201, 119, 107, 1643, 2779, 778, 8393, 170, 146, 9972, 22300, 4763, 22283, 131, 107, 3396, 346, 15212, 2839, 125, 1434, 260, 4486, 179, 3983, 1191, 117, 346, 117, 449, 1061, 311, 11967, 490, 5863, 122, 17891, 2822, 7343, 13071, 107, 195, 3979, 128, 197, 119, 787, 1984, 22288, 123, 5294, 356, 107, 117, 10821, 119, 15708, 22282, 366, 6363, 171, 998, 262, 230, 4036, 170, 4251, 125, 4014, 2479, 119, 9755, 20509, 2364, 325, 13683, 122, 117, 10012, 201, 240, 2205, 805, 5587, 122, 146, 3695, 10259, 3213, 138, 117, 170, 1977, 1021, 13839, 229, 1037, 171, 10345, 117, 20523, 22288, 125, 576, 3876, 1160, 1147, 119, 107, 4499, 179, 1784, 244, 7122, 2490, 202, 998, 117, 146, 2205, 805, 5587, 117, 3620, 171, 998, 117, 311, 2628, 221, 1434, 14190, 125, 3822, 119, 787, 311, 11234, 1016, 131, 107, 19900, 249, 117, 3983, 346, 253, 2357, 117, 253, 3620, 107, 119, 761, 9834, 4566, 3846, 770, 13540, 3307, 203, 2745, 195, 3979, 128, 197, 119, 3396, 1684, 8766, 185, 22283, 117, 449, 262, 146, 998, 179, 311, 2002, 6272, 125, 3866, 1966, 3420, 107, 117, 3415, 119, 107, 231, 4755, 269, 3213, 138, 770, 495, 7343, 3695, 180, 1126, 171, 10345, 122, 368, 407, 1191, 146, 998, 171, 9972, 22300, 119, 989, 7343, 2475, 117, 122, 311, 2628, 221, 123, 13878, 22282, 185, 117, 173, 6437, 119, 787, 1996, 179, 978, 2448, 2895, 170, 1039, 122, 179, 5220, 682, 698, 16643, 8840, 5062, 173, 222, 5340, 119, 787, 11234, 179, 146, 8846, 262, 2514, 1752, 179, 123, 681, 5664, 179, 368, 1191, 625, 1365, 22288, 262, 5961, 170, 1039, 119, 20564, 117, 368, 311, 2628, 4922, 4067, 125, 3822, 179, 5794, 1210, 6362, 22247, 22281, 107, 117, 10821, 119, 1431, 4733, 20502, 285, 240, 248, 192, 278, 257, 192, 267, 192, 113, 137, 2779, 514, 846, 185, 114, 1012, 123, 1018, 4756, 6880, 125, 3822, 179, 9755, 20509, 1367, 123, 11589, 146, 21211, 10326, 119, 231, 652, 1518, 262, 173, 1614, 125, 14979, 22307, 117, 449, 368, 9679, 179, 11736, 2822, 3996, 117, 346, 2686, 333, 107, 222, 4249, 125, 222, 2232, 1518, 107, 119, 1645, 368, 18047, 22288, 123, 8405, 171, 1518, 122, 259, 8244, 4058, 123, 5401, 3093, 4803, 325, 122, 325, 202, 1423, 171, 2200, 119, 533, 4754, 3063, 4058, 123, 17755, 307, 117, 146, 179, 8231, 744, 325, 327, 6698, 119, 107, 3396, 9679, 179, 2471, 179, 2822, 3996, 122, 346, 1203, 3767, 230, 576, 119, 177, 4102, 556, 705, 19973, 785, 119, 989, 4490, 5961, 125, 820, 222, 2113, 376, 5747, 9349, 119, 11408, 117, 4264, 202, 17933, 122, 1790, 202, 18868, 22317, 22346, 117, 180, 6090, 119, 5685, 743, 117, 9481, 7788, 117, 2205, 117, 4097, 159, 12460, 181, 117, 19532, 7902, 22280, 117, 8928, 1515, 249, 8378, 117, 2891, 1404, 339, 117, 7593, 117, 171, 3217, 119, 119, 119, 4859, 1061, 6082, 22287, 7600, 119, 385, 1145, 125, 2538, 117, 2475, 107, 117, 8028, 119, 1629, 298, 8244, 170, 1976, 656, 325, 6802, 10248, 117, 9755, 20509, 407, 5971, 125, 7505, 3724, 12283, 1628, 119, 107, 989, 1684, 4062, 3852, 230, 3661, 179, 3306, 2351, 123, 6384, 173, 2182, 125, 7614, 119, 14233, 4435, 22279, 1257, 170, 1039, 119, 989, 230, 547, 7211, 125, 4915, 123, 3661, 125, 2538, 407, 538, 17080, 8244, 119, 3396, 1120, 3897, 22283, 122, 253, 2199, 1569, 222, 3767, 582, 2448, 252, 119, 1643, 7277, 2538, 229, 2375, 117, 260, 9880, 1835, 22286, 6262, 176, 5334, 2227, 123, 347, 2748, 119, 20805, 834, 7672, 119, 7170, 346, 9050, 202, 2182, 117, 449, 2745, 179, 787, 659, 253, 13380, 107, 117, 8028, 119, 102], 'label': '5'}\n",
            "{'text': [101, 21791, 183, 179, 12069, 7937, 117, 3869, 173, 8446, 122, 2391, 19083, 291, 19586, 442, 4188, 423, 4884, 291, 12605, 423, 2831, 123, 4137, 1955, 2321, 18468, 122, 14809, 1965, 119, 21791, 183, 179, 12069, 7937, 117, 3869, 173, 8446, 122, 2391, 19083, 291, 19586, 442, 4188, 423, 4884, 291, 12605, 423, 2831, 123, 4137, 1955, 2321, 18468, 122, 14809, 1965, 119, 7437, 384, 4264, 412, 1582, 5559, 125, 19259, 122, 5686, 173, 4080, 412, 5581, 22263, 526, 9475, 1080, 117, 262, 12102, 180, 15492, 125, 200, 119, 1033, 240, 4167, 481, 122, 6095, 222, 20837, 498, 2200, 2642, 202, 359, 7918, 1065, 4155, 119, 1040, 120, 16720, 120, 14979, 22302, 16720, 22296, 554, 177, 4468, 125, 10855, 17727, 171, 3118, 171, 10967, 117, 13970, 251, 229, 6151, 118, 14258, 117, 700, 180, 4076, 240, 245, 123, 205, 221, 146, 20111, 2151, 2607, 21760, 117, 412, 2171, 21941, 180, 10455, 117, 9938, 222, 1223, 125, 1256, 481, 122, 3003, 2112, 179, 495, 6648, 229, 563, 2061, 175, 1837, 125, 598, 4347, 122, 1907, 3498, 125, 5409, 143, 179, 8413, 202, 2200, 1910, 119, 761, 123, 4867, 125, 14120, 411, 3909, 22283, 117, 146, 4022, 1307, 325, 596, 202, 2466, 173, 222, 2504, 180, 681, 3007, 1772, 1425, 123, 333, 2255, 304, 117, 179, 15594, 146, 2094, 118, 13293, 1065, 1543, 171, 622, 3714, 122, 2286, 229, 2338, 1318, 123, 6831, 221, 123, 4960, 177, 119, 7178, 179, 347, 1254, 229, 2403, 113, 1528, 125, 222, 622, 122, 1256, 2112, 117, 770, 179, 368, 262, 4775, 173, 1934, 125, 1543, 114, 4048, 548, 13779, 251, 229, 7315, 170, 259, 2851, 325, 5533, 2370, 125, 736, 1775, 179, 4366, 670, 298, 1867, 5490, 270, 171, 2200, 2835, 119, 335, 230, 2925, 170, 297, 298, 1649, 9776, 4644, 171, 4659, 113, 1242, 180, 2092, 117, 1256, 366, 13946, 122, 325, 1256, 180, 5472, 114, 117, 146, 771, 253, 6086, 173, 179, 146, 4022, 1307, 325, 596, 173, 222, 653, 1774, 2080, 240, 1957, 119, 510, 7825, 179, 325, 176, 4621, 22287, 171, 4732, 125, 2255, 304, 453, 14458, 17502, 122, 6305, 171, 1422, 119, 4114, 22281, 682, 1775, 117, 259, 5409, 143, 325, 5533, 2370, 113, 15642, 608, 1182, 22331, 3802, 14944, 22283, 122, 15688, 3237, 118, 233, 8315, 114, 6179, 228, 532, 7744, 5662, 173, 3975, 125, 6437, 119, 119, 119, 291, 1547, 117, 222, 622, 122, 1423, 1075, 171, 5278, 171, 2504, 15950, 119, 4823, 1028, 2844, 171, 1147, 12890, 2642, 246, 240, 346, 4832, 5747, 4500, 399, 170, 8549, 8091, 170, 2851, 7227, 125, 380, 436, 16306, 259, 14764, 122, 10384, 4594, 119, 3278, 117, 3787, 122, 8461, 744, 1854, 173, 3418, 2851, 179, 506, 9128, 22281, 202, 995, 11445, 125, 5096, 119, 15940, 247, 1861, 324, 2858, 22280, 113, 8660, 833, 22305, 2598, 8139, 114, 122, 1333, 193, 22296, 2627, 314, 113, 13952, 470, 186, 22326, 114, 548, 11006, 3810, 4644, 179, 12903, 228, 675, 15054, 22281, 117, 449, 5072, 172, 5589, 6592, 113, 3346, 183, 22292, 114, 117, 346, 119, 2781, 171, 1342, 1341, 171, 9969, 180, 4500, 399, 117, 1134, 1195, 122, 3734, 3615, 5409, 143, 179, 770, 8955, 228, 6710, 125, 230, 1490, 11374, 214, 146, 653, 2504, 119, 231, 325, 5533, 378, 125, 944, 253, 4269, 1937, 1056, 117, 179, 698, 353, 2375, 171, 15526, 18162, 5618, 1065, 1617, 125, 3665, 119, 4114, 596, 1364, 117, 368, 2473, 222, 1461, 180, 213, 18741, 113, 3757, 114, 122, 864, 5596, 171, 3219, 10265, 119, 4823, 834, 3484, 15844, 1307, 1256, 481, 117, 368, 698, 5533, 125, 370, 146, 2466, 6548, 243, 119, 2781, 146, 1910, 6290, 1392, 15738, 22283, 117, 353, 2375, 171, 11158, 207, 1065, 3190, 117, 3390, 2535, 146, 11165, 171, 347, 1223, 119, 503, 1318, 19023, 117, 3180, 123, 3805, 298, 9743, 180, 3928, 3391, 10953, 119, 192, 117, 173, 1512, 117, 262, 2700, 118, 3176, 171, 2088, 125, 13154, 117, 170, 2368, 123, 2434, 498, 146, 9801, 529, 11479, 119, 503, 8062, 8755, 117, 2440, 180, 7989, 125, 8715, 3213, 22279, 1857, 117, 179, 5733, 8955, 1027, 481, 271, 3161, 171, 7802, 125, 22035, 173, 1512, 117, 1307, 423, 1528, 222, 4022, 325, 5533, 378, 179, 368, 131, 5816, 22300, 11059, 514, 5528, 3552, 117, 179, 15594, 146, 2299, 424, 1065, 1618, 125, 3618, 119, 192, 1257, 2113, 123, 1478, 1367, 123, 636, 670, 2811, 1254, 229, 3437, 125, 3378, 180, 4179, 171, 2236, 17798, 119, 2067, 1659, 117, 259, 14764, 171, 1774, 1684, 13031, 228, 179, 123, 6234, 171, 1223, 117, 179, 2810, 20250, 202, 1338, 180, 1318, 117, 240, 3087, 171, 1946, 5409, 117, 495, 123, 1407, 8208, 119, 3585, 131, 4269, 1937, 1056, 117, 202, 15526, 18162, 5618, 1065, 1617, 120, 3665, 22311, 22352, 22348, 6162, 22317, 131, 6290, 1392, 15738, 22283, 117, 202, 11158, 207, 1065, 1618, 120, 3190, 22324, 5650, 22320, 22402, 22301, 131, 5816, 22300, 11059, 514, 5528, 3552, 117, 202, 2299, 424, 1065, 1618, 120, 3618, 13209, 7665, 18394, 131, 8715, 3213, 22279, 1857, 117, 202, 7802, 125, 22035, 1065, 1512, 120, 3618, 9369, 13344, 7665, 18394, 131, 10204, 6817, 1361, 117, 202, 12511, 7002, 1065, 1512, 120, 3618, 22318, 22352, 22327, 22328, 6162, 22301, 131, 1419, 3073, 14495, 22326, 117, 202, 13197, 22290, 185, 3854, 22279, 705, 1065, 1512, 120, 3618, 10722, 22322, 22379, 22320, 5234, 131, 1651, 6505, 22087, 22284, 22282, 6332, 12764, 16339, 22285, 117, 202, 1305, 324, 1065, 1570, 120, 3470, 7073, 22328, 10847, 16017, 22322, 5650, 131, 17174, 10239, 2041, 117, 202, 4397, 22285, 2229, 1065, 1511, 120, 3470, 22357, 10409, 22321, 21748, 22301, 131, 5268, 2057, 604, 21825, 117, 202, 448, 22308, 22328, 19244, 22290, 1065, 1618, 120, 3757, 6765, 6993, 8427, 7073, 22301, 131, 7593, 17578, 2222, 117, 202, 13118, 2911, 185, 1065, 1592, 120, 3843, 22333, 7864, 16484, 131, 3455, 22280, 4095, 157, 8816, 1750, 9500, 22278, 117, 202, 231, 343, 9965, 343, 1065, 1154, 14214, 397, 120, 4284, 9436, 22357, 22327, 5234, 131, 17173, 7806, 22280, 7684, 1840, 4029, 117, 229, 9140, 1053, 154, 1065, 1592, 120, 4284, 20928, 10847, 22320, 9545, 131, 12251, 896, 22331, 22261, 117, 202, 335, 2614, 1065, 1618, 120, 4284, 22310, 8718, 22321, 22341, 17694, 22327, 131, 8159, 8667, 117, 202, 2268, 1065, 1618, 120, 5096, 17511, 7073, 22301, 131, 15940, 247, 1861, 324, 2858, 22280, 117, 202, 8660, 833, 22305, 2598, 8139, 1065, 1617, 120, 5096, 22322, 22371, 6236, 5234, 131, 5072, 172, 5589, 6592, 117, 202, 3346, 183, 22292, 1065, 1512, 120, 5096, 22321, 15289, 22349, 22341, 5234, 131, 1333, 193, 22296, 2627, 314, 117, 202, 13952, 470, 186, 22326, 1065, 1512, 120, 5096, 6765, 22357, 14390, 22301, 16566, 22341, 18822, 5118, 131, 15642, 608, 1182, 22331, 3802, 14944, 22283, 117, 202, 2090, 252, 1065, 1618, 120, 6437, 5218, 7286, 5234, 15040, 200, 18199, 131, 15688, 3237, 118, 233, 8315, 117, 202, 17264, 22293, 10911, 22285, 8139, 1065, 1600, 120, 6437, 14213, 4089, 13292, 131, 2255, 304, 117, 202, 2094, 118, 13293, 1065, 1543, 120, 14979, 22307, 115, 820, 420, 259, 7579, 180, 681, 3007, 1772, 113, 213, 18741, 117, 202, 1652, 298, 3585, 114, 102], 'label': '5'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPypCNPuHaRz"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvy3rgrdHj_x"
      },
      "source": [
        "'''É preciso informar o número de labels, pois o BERTimbau foi treinado para 2 classes '''\n",
        "class BERT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "\n",
        "        options_name = \"bert-base-portuguese-cased\"\n",
        "        self.encoder = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased',num_labels=9 )\n",
        "\n",
        "    def forward(self, text, label):\n",
        "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
        "\n",
        "        return loss, text_fea\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pYKbHICIus0"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJFwyl7DIoxQ"
      },
      "source": [
        "# Save and Load Functions\n",
        "\n",
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    \n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "\n",
        "def load_metrics(load_path):\n",
        "\n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiueExF5Jb8V"
      },
      "source": [
        "# Training Function\n",
        "'''criterion = nn.BCELoss() é BinaryCrossEntropy é a função de perda para targets binarios. Como o nosso alvo possui\n",
        "muitas classes troque a função de perda para nn.CrossEntropyLoss() '''\n",
        "\n",
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion = nn.CrossEntropyLoss(), #nn.BCELoss(),\n",
        "          train_loader = train_iter,\n",
        "          valid_loader = valid_iter,\n",
        "          num_epochs = 5,\n",
        "          eval_every = len(train_iter) // 2,\n",
        "          file_path = destination_folder,\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "    \n",
        "    # initialize running values\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    # training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for (text, labels), _ in train_loader:\n",
        "            labels = labels.type(torch.LongTensor)           \n",
        "            #print('label size:', labels.size())\n",
        "            #print('label:', labels)\n",
        "            labels = labels.to(device)\n",
        "            text = text.type(torch.LongTensor) \n",
        "            #print('text:', text.size())\n",
        "            text = text.to(device)\n",
        "            #print('treina...')\n",
        "            output = model(text, labels)\n",
        "            #print('fim treino...')\n",
        "            loss, _ = output\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update running values\n",
        "            running_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            # evaluation step\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():                    \n",
        "\n",
        "                    # validation loop\n",
        "                    for (text,labels), _ in valid_loader:\n",
        "                        text = text.type(torch.LongTensor)  \n",
        "                        text = text.to(device)\n",
        "                        labels = labels.type(torch.LongTensor)           \n",
        "                        labels = labels.to(device)\n",
        "                        \n",
        "                        output = model(text, labels)\n",
        "                        loss, _ = output\n",
        "                        \n",
        "                        valid_running_loss += loss.item()\n",
        "\n",
        "                # evaluation\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                # resetting running values\n",
        "                running_loss = 0.0                \n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                # print progress\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "                \n",
        "                # checkpoint\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
        "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    \n",
        "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    print('Finished Training!')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQcJQ5kaMPa4",
        "outputId": "82184e7e-c385-4dd0-b25a-6fb43fcfde60"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrkvwE2VL1qY",
        "outputId": "27ada042-9713-470b-e1c9-5bd6e6aca6fe"
      },
      "source": [
        "model = BERT().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "train(model=model, optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [40/400], Train Loss: 1.9647, Valid Loss: 1.8218\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [1/5], Step [80/400], Train Loss: 1.6679, Valid Loss: 1.3062\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [2/5], Step [120/400], Train Loss: 1.2497, Valid Loss: 0.9376\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [2/5], Step [160/400], Train Loss: 0.8751, Valid Loss: 0.6886\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [3/5], Step [200/400], Train Loss: 0.7224, Valid Loss: 0.5602\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [3/5], Step [240/400], Train Loss: 0.5159, Valid Loss: 0.4799\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [4/5], Step [280/400], Train Loss: 0.4663, Valid Loss: 0.4406\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [4/5], Step [320/400], Train Loss: 0.3260, Valid Loss: 0.4078\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Epoch [5/5], Step [360/400], Train Loss: 0.3361, Valid Loss: 0.4088\n",
            "Epoch [5/5], Step [400/400], Train Loss: 0.2275, Valid Loss: 0.3417\n",
            "Model saved to ==> /content/model.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Model saved to ==> /content/metrics.pt\n",
            "Finished Training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "AHdfTUs0ALnZ",
        "outputId": "deb30c53-c737-49ed-98d4-13ef6eda7bad"
      },
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== /content/metrics.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAI0EpQOAgM1"
      },
      "source": [
        "### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sGfCMMB9ewJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "7b534063-17d9-451d-dbe9-880c8516ef92"
      },
      "source": [
        "def evaluate(model, test_loader):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (text, labels), _ in test_loader:\n",
        "                labels = labels.type(torch.LongTensor)           \n",
        "                labels = labels.to(device)\n",
        "                text = text.type(torch.LongTensor)  \n",
        "                text = text.to(device)\n",
        "                output = model(text, labels)\n",
        "\n",
        "                _, output = output\n",
        "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "                y_true.extend(labels.tolist())\n",
        "    \n",
        "    print('Classification Report:')\n",
        "    n_classe = np.max(y_true)+1\n",
        "    print(classification_report(y_true, y_pred, labels=np.arange(0,n_classe), digits=4))\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(0,n_classe))\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "\n",
        "    \n",
        "    \n",
        "best_model = BERT().to(device)\n",
        "\n",
        "load_checkpoint(destination_folder + '/model.pt', best_model)\n",
        "\n",
        "evaluate(best_model, test_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== /content/model.pt\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9565    0.9565    0.9565        23\n",
            "           1     0.7857    1.0000    0.8800        22\n",
            "           2     0.8636    0.8636    0.8636        22\n",
            "           3     1.0000    1.0000    1.0000        14\n",
            "           4     0.7619    0.8889    0.8205        18\n",
            "           5     1.0000    1.0000    1.0000        15\n",
            "           6     0.9231    0.7059    0.8000        17\n",
            "           7     0.8750    0.7241    0.7925        29\n",
            "\n",
            "    accuracy                         0.8812       160\n",
            "   macro avg     0.8957    0.8924    0.8891       160\n",
            "weighted avg     0.8879    0.8812    0.8794       160\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIA9kWsxs7SQ"
      },
      "source": [
        "## Salvando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg_nC_Pyu7vn",
        "outputId": "ab5cb864-64ed-41aa-a541-53bf88f66019"
      },
      "source": [
        "from google.colab import files, drive\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/Colab\\ Notebooks/nlp_tcc\n",
        "path = '/gdrive/My Drive/Colab Notebooks/nlp_tcc'\n",
        "arquivo = '/bertimbau_classifier_pt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/Colab Notebooks/nlp_tcc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuUSiZFswnGs"
      },
      "source": [
        "pickle.dump(best_model, open(path+arquivo,'wb'))\n",
        "pickle.dump(tokenizer, open(path+arquivo+'_token','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBuMztZ-gwyN"
      },
      "source": [
        "## Aplicando o modelo nas miscelâneas de notícias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBAsMn2o3rGc"
      },
      "source": [
        "#carregando o modelo e o tokenizador\n",
        "model = pickle.load(open(path+arquivo,'rb'))\n",
        "token = pickle.load(open(path+arquivo+'_token','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnFvPwrWgnX5"
      },
      "source": [
        "### Tokenizando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTxwEmKpjmjR"
      },
      "source": [
        "# TabularDataset\n",
        "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
        "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
        "fields = [('text', text_field)]\n",
        "\n",
        "miscelanea = TabularDataset.splits(path=source_folder, miscelanea='miscelanea.csv', \n",
        "                                  format='CSV',fields=fields, skip_header=True)\n",
        "\n",
        "# Iterators\n",
        "\n",
        "miscelanea_iter = BucketIterator(miscelanea, batch_size=bs, sort_key=lambda x: len(x.text),\n",
        "                            device=device, train=True, sort=True, sort_within_batch=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1koq2k7jrIj",
        "outputId": "c5577499-6f5d-46d0-9898-70effe92e8e7"
      },
      "source": [
        "tokenizer(\"Hoje é um belo dia de sábado, porém estou aqui estudando.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 6029, 253, 222, 15152, 644, 125, 14157, 117, 1804, 12044, 5863, 19679, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJrH6W-UEXCK"
      },
      "source": [
        ""
      ]
    }
  ]
}