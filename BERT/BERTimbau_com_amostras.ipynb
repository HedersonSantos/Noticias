{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTimbau_com_amostras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HedersonSantos/Noticias/blob/main/BERT/BERTimbau_com_amostras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKMj5WG6lxGP",
        "outputId": "91511a38-9e8f-418b-fca3-cfa63d1cd330"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIlZbdsGo_vR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df757cc-8859-4517-f70b-0d26e9e1bc85"
      },
      "source": [
        "\n",
        "!pip install torch==1.8.1 torchvision==0.9.1 torchaudio==0.8.\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.8.1\n",
            "  Using cached torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "Collecting torchvision==0.9.1\n",
            "  Using cached torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
            "Collecting torchaudio==0.8.\n",
            "  Using cached torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==1.8.1, torchaudio==0.8.0 and torchvision==0.9.1 because these package versions have conflicting dependencies.\u001b[0m\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.8.1\n",
            "    torchvision 0.9.1 depends on torch==1.8.1\n",
            "    torchaudio 0.8.0 depends on torch==1.8.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky7aWx6DyYU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021e1d21-e924-422c-a85f-90311b8011ab"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 21 14:27:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0    31W /  70W |   2898MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hts6ewoYvUYn"
      },
      "source": [
        "# Libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from google.colab import files, drive\n",
        "import io, os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "palette = sns.color_palette(\"bright\", 10)\n",
        "\n",
        "# Preliminaries\n",
        "\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "\n",
        "# Models\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from transformers import AutoTokenizer  # Or BertTokenizer\n",
        "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n",
        "from transformers import AutoModel  # or BertModel, for BERT without pretraining heads\n",
        "\n",
        "# Training\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score, precision_score, \\\n",
        "                            recall_score, confusion_matrix, \\\n",
        "                            plot_confusion_matrix, classification_report, \\\n",
        "                            balanced_accuracy_score, cohen_kappa_score, matthews_corrcoef\n",
        "import seaborn as sns"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPOdGbGitPHS"
      },
      "source": [
        "### Carregando tokens e vocabulário do BERTimbau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLcgDJZSpmfD",
        "outputId": "a13eee39-8687-453c-f116-7cfd9dd33b1f"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFtrA_dtunW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ffe18e-76e8-42ab-ad5e-95d4913bf2d4"
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/Colab\\ Notebooks\n",
        "path = '/gdrive/My Drive/Colab Notebooks'\n",
        "KEY='4/1AX4XfWjFfXOpQF_Lhhwz8Sp5DTauJAEXNDQjx66Khyme5ASsCvDLtcqsBX0'"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgHctA-zJTMu"
      },
      "source": [
        "#model.save_pretrained('./amostra_news_integrada/bertimbau_base')\n",
        "#tokenizer.save_pretrained('./amostra_news_integrada/bertimbau_base')\n",
        "# .save_vocabulary('./amostra_news_integrada/bertimbau_base')\n",
        "#tokenizer = AutoModel.from_pretrained('./amostra_news_integrada/bertimbau_base')\n",
        "#model = AutoModel.from_pretrained('./amostra_news_integrada/bertimbau_base')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZOL2o_ltyzz"
      },
      "source": [
        "### Preparando DataSet\n",
        "https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFFldLWvV6Mg"
      },
      "source": [
        "#%cd amostra_news_integrada\n",
        "#!unzip amostra_news_integrada-20210815T184936Z-001.zip\n",
        "#!ls -lh\n",
        "#!ls  amostra_news_integrada/amostra_2\n",
        "#!mkdir bertimbau_all_categ\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfj3koMmWsZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5d52d1-540a-4d8e-b90d-b55cd7c7950f"
      },
      "source": [
        "#!mkdir ./bertimbau_all_categ/amostra_4\n",
        "!ls ./bertimbau_resp/9"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedd.pt  metrics.pt  model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV8T4nMYXqdR",
        "outputId": "b6a035a2-1311-4117-b438-98bae0df440a"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sjrTvfBLGCL"
      },
      "source": [
        "source_folder = './amostra_news_integrada/amostra_' #'/content'\n",
        "destination_folder = './bertimbau_resp' #'/content'\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90WJxOxcxgAQ"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyoK7ac8t4HF"
      },
      "source": [
        "#https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613\n",
        "#Model hyper-parameter\n",
        "MAX_SEQ_LEN = 512 #limita os artigos em 128 tokens. BERTimbau base é limitado em 512 tokens por texto.\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
        "bs = 2\n",
        "lr = 1e-6\n",
        "\n",
        "\n",
        "def montaFields(MAX_SEQ_LEN):\n",
        "  # Fields - use_vocab=False  e tokenizer.encode permite que utilizemos os tokens do BERTimbau.\n",
        "  label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
        "  text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
        "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
        "  fields = [('text', text_field),('label', label_field)]\n",
        "  return [label_field, text_field, fields]\n",
        "\n",
        "label_field, text_field, fields = montaFields(MAX_SEQ_LEN)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5glQN-oBt4m"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqRpEtW1OuqC"
      },
      "source": [
        "def tokenizaAmostra(source_folder, fields=fields, soTeste=False):\n",
        "  # TabularDataset\n",
        "  train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='valid.csv',\n",
        "                                            test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
        "  # Iterators\n",
        "\n",
        "  if soTeste == False:\n",
        "    train_iter = BucketIterator(train, batch_size=bs, sort_key=lambda x: len(x.text),\n",
        "                              device=device, train=True, sort=True, sort_within_batch=True)\n",
        "    valid_iter = BucketIterator(valid, batch_size=bs, sort_key=lambda x: len(x.text),\n",
        "                              device=device, train=True, sort=True, sort_within_batch=True)\n",
        "    test_iter = Iterator(test, batch_size=bs, device=device, train=False, shuffle=False, sort=False)\n",
        "  else:\n",
        "      train_iter, valid_iter = None, None\n",
        "      test_iter = Iterator(test, batch_size=bs, device=device, train=False, shuffle=False, sort=False)\n",
        "  return [train_iter, valid_iter, test_iter]\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8maI4HcbPukL"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcTHSXSluKkt"
      },
      "source": [
        "#print(vars(train[0]))\n",
        "#print(vars(valid[0]))\n",
        "#print(vars(test[0]))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPypCNPuHaRz"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvy3rgrdHj_x"
      },
      "source": [
        "'''É preciso informar o número de labels '''\n",
        "class BERT(nn.Module):\n",
        "\n",
        "    def __init__(self, qtd_categories):\n",
        "        super(BERT, self).__init__()\n",
        "\n",
        "        options_name = \"bert-base-portuguese-cased\"\n",
        "        self.encoder = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased',num_labels=qtd_categories )\n",
        "\n",
        "    def forward(self, text, label):\n",
        "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
        "        \n",
        "        return loss, text_fea\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pYKbHICIus0"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJFwyl7DIoxQ"
      },
      "source": [
        "# Save and Load Functions\n",
        "\n",
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    \n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "\n",
        "def load_metrics(load_path):\n",
        "\n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n",
        "\n",
        "def save_embedding(save_path, embedding):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    emb_dict = {'_': embedding}\n",
        "    \n",
        "    torch.save(emb_dict, save_path)\n",
        "    print(f'Embedding saved to ==> {save_path}')\n",
        "\n",
        "def load_embedding(load_path):\n",
        "\n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    emb_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Embedding loaded from <== {load_path}')\n",
        "    \n",
        "    return emb_dict\n",
        "\n",
        "def create_directory(path, directory):\n",
        "  try:\n",
        "    os.makedirs(path + '/' + directory)\n",
        "  except FileExistsError:\n",
        "    # directory already exists\n",
        "    pass"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiueExF5Jb8V"
      },
      "source": [
        "# Training Function\n",
        "'''criterion = nn.BCELoss() é BinaryCrossEntropy é a função de perda para targets binarios. Como o nosso alvo possui\n",
        "muitas classes troque a função de perda para nn.CrossEntropyLoss() '''\n",
        "\n",
        "def train(model,\n",
        "          optimizer,\n",
        "          train_loader ,\n",
        "          valid_loader ,\n",
        "          eval_every ,\n",
        "          file_path ,\n",
        "          criterion = nn.CrossEntropyLoss(), #nn.BCELoss(),\n",
        "          num_epochs = 5,\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "    \n",
        "    \n",
        "    print('1 - inicializando variávies')\n",
        "    # initialize running values\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    # training loop\n",
        "    print('1 - inicializando treinamento')\n",
        "    model.train() #habilita os valores dos pesos do modelo para treinamento\n",
        "    for epoch in range(num_epochs):\n",
        "        X = []  \n",
        "        for (text, labels), _ in train_loader:\n",
        "            labels = labels.type(torch.LongTensor)  #carrega as categorias para pytorch         \n",
        "            labels = labels.to(device) # disponibiliza para as GPU\n",
        "            text = text.type(torch.LongTensor) #carrega os tokens do texto para pytorch        \n",
        "            text = text.to(device) #disponibiliza para as GPU\n",
        "            output = model(text, labels) #efetua o treinamento no modelo bert carregado\n",
        "            loss, _ = output #obtem o valor da função loss do texto treinado\n",
        "\n",
        "            optimizer.zero_grad() #limpa os gradientes do último treino (zera tudo)\n",
        "            loss.backward() #calcula a derivada da função perda em relação aos parâmetros\n",
        "            optimizer.step() #atualiza os pesos fazendo com que o otimizador dê um passo com base no gradiente dos parâmetros\n",
        "\n",
        "            # update running values\n",
        "            running_loss += loss.item() #acumula o valor da função loss\n",
        "            global_step += 1\n",
        "            #X.extend(_.tolist())\n",
        "            # evaluation step - roda o modelo para o token de validação, obtém o valor da função loss e tira a média para o treinamento e validação.\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval() # seta as camadas dropout e batch normalization \n",
        "                with torch.no_grad():                    \n",
        "                   \n",
        "                    # validation loop\n",
        "                    for (text,labels), _ in valid_loader:\n",
        "                        text = text.type(torch.LongTensor)  \n",
        "                        text = text.to(device)\n",
        "                        labels = labels.type(torch.LongTensor)           \n",
        "                        labels = labels.to(device)\n",
        "                        \n",
        "                        output = model(text, labels)\n",
        "                        loss, _ = output\n",
        "                        \n",
        "                        valid_running_loss += loss.item()\n",
        "                        \n",
        "                \n",
        "                    \n",
        "\n",
        "                # evaluation\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                # resetting running values\n",
        "                running_loss = 0.0                \n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                # print progress\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "                \n",
        "                # checkpoint\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
        "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "                    \n",
        "        print(X)\n",
        "        save_embedding(file_path + '/' + 'embedd.pt', X)\n",
        "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    #save_embedding(file_path + '/' + 'embedd.pt', X)\n",
        "    print('Finished Training!')\n",
        "    "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQcJQ5kaMPa4",
        "outputId": "e747d8cf-64da-4df2-f3a4-13244c75a965"
      },
      "source": [
        "device"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrkvwE2VL1qY",
        "outputId": "a8ae64b7-d475-4367-fcf0-ef875a53029b"
      },
      "source": [
        "%%time\n",
        "!NotebookApp.iopub_data_rate_limit = 1048576000000\n",
        "qtd_categories=[10]\n",
        "#token_train, token_valid, token_test = [],[],[]\n",
        "id_planilha = [9.2]\n",
        "dataset = [5]\n",
        "n_epoca = 4\n",
        "for idx, (id_, amostra) in enumerate(zip(id_planilha,dataset)):\n",
        "  create_directory(destination_folder,str(id_))\n",
        "  file_path = destination_folder + \"/\"+str(id_)\n",
        "  print(file_path)\n",
        "  model = BERT(qtd_categories=qtd_categories[idx]).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  inicio = datetime.now()\n",
        "  print('Treinando amostra:', amostra, 'inicio:', inicio)\n",
        "  tokens = tokenizaAmostra(source_folder+str(amostra))\n",
        "  train(model=model, \n",
        "      optimizer=optimizer,\n",
        "      num_epochs=n_epoca,\n",
        "      train_loader=tokens[0],\n",
        "      valid_loader=tokens[1],\n",
        "      eval_every=len(tokens[0]) // 2, #tamanho do dataset de treinamento / 2 (chão)\n",
        "      file_path=file_path)\n",
        "  print('Duracao:', datetime.now()-inicio)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: NotebookApp.iopub_data_rate_limit: command not found\n",
            "./bertimbau_resp/9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbLMFDrarFbW"
      },
      "source": [
        "## Valor da função LOSS na descida do gradiente \n",
        "por id de experimento registrado na planilha de controle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHdfTUs0ALnZ"
      },
      "source": [
        "id_planilha = [9,9.1,9.2,9.3]\n",
        "for id_ in id_planilha:\n",
        "  file_path = destination_folder + \"/\"+str(id_)\n",
        "  train_loss_list, valid_loss_list, global_steps_list = load_metrics(file_path + '/metrics.pt')\n",
        "  plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "  plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "  plt.xlabel('Global Steps')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title = 'Resultado do Treino id ' + str(id_)\n",
        "  plt.legend()\n",
        "  plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAI0EpQOAgM1"
      },
      "source": [
        "### Avaliação\n",
        "* https://towardsdatascience.com/evaluating-categorical-models-e667e17987fd\n",
        "* https://towardsdatascience.com/evaluating-categorical-models-ii-sensitivity-and-specificity-e181e573cff8\n",
        "* https://towardsdatascience.com/metrics-for-imbalanced-classification-41c71549bbb5\n",
        "* https://towardsdatascience.com/multi-class-classification-extracting-performance-metrics-from-the-confusion-matrix-b379b427a872\n",
        "* https://towardsdatascience.com/matthews-correlation-coefficient-when-to-use-it-and-when-to-avoid-it-310b3c923f7e\n",
        "* https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2 \n",
        "*https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1\n",
        "* https://towardsdatascience.com/multi-class-metrics-made-simple-the-kappa-score-aka-cohens-kappa-coefficient-bdea137af09c\n",
        "* https://thedatascientist.com/performance-measures-cohens-kappa-statistic/\n",
        "* Material de aula do Professor André\n",
        "* Material do curso MicroSoft\n",
        "* Predictive Accuracy: A Misleading Performance Measure for Highly Imbalanced Data (sas_metrics.pdf) Paper 942-2017 (Josephine S Akosa, Oklahoma State University)\n",
        "\n",
        "\n",
        "VP = VERDADEIRO POSITIVO<br>\n",
        "VN = VERDADEIRO NEGATIVO<br>\n",
        "FP = FALSO POSITIVO<br>\n",
        "FN = FALSON NEGATIVO<br>\n",
        "TVP = TAXA DE VERDADEIRO POSITIVO<br>\n",
        "TVN = TAXA DE VERDADEIRO NEGATIVO<br>\n",
        "TFP = TAXA DE FALSO POSITIVO<br>\n",
        "TFN = TAXA DE FALSO NEGATIVO<br>\n",
        "\n",
        "Métricas utilizadas:<br>\n",
        "\n",
        "* **Acurácia:** proporção de classificações corretas feitas pelo modelo.<br>\n",
        "        Acurácia = (VP + VN)/(VP+VN+VP+VN)<br>\n",
        "\n",
        "* **Precisão:** proporção correta de classificação feita para uma determinada classe.<br>\n",
        "        Precisão = (VP)/(VP + FP)\n",
        "\n",
        "* **Revocação ou Sensibilidade:** proporção de classificações corretas de VP feitas para uma determinada classe considerando todas as instâncias do dataset de testes.<br>\n",
        "      Revocação = TVP = (VP)/(VP+FN)\n",
        "\n",
        "* **Especificidade:** proporção de classificações corretas de VN feitas para uma determinada classe considerando todas as instâncias do dataset de testes.\n",
        "      Especificidade = TVN = (VN)/(VN + FP)\n",
        "\n",
        "* **Suporte:** quantidade de instâncias de uma determinada classe no dataset de testes.\n",
        "\n",
        "**Para o DataSet 3 - dados desbalanceados**\n",
        "\n",
        "* **F1 é a média harmônica da precisão e da revocação.<br>\n",
        "\n",
        "      F1 = (2 * VP) / (2 * VP + FP + FN)\n",
        "* **MCC:** é o coeficiente de correlação Matthews que é utilizado para classes com tamanhos diferentes. Possui escala entre -1 e 1, sendo que 1 indica uma perfeita predição, 0 representa uma predição aleatória e -1 indica discordância total dos valores preditos e os valores verdadeiros.  \n",
        "\n",
        "      MCC = (VP*VN - FP*FN) / (SQRT(VP+FP)*(VP+FN)*(VN+FP)*(VN+FN)\n",
        "      \n",
        "\n",
        "* **Kappa Score - Cohen's Kappa Coefficient** informa quão melhor o classificador está se saindo em relação ao desempenho de um classificador que simplesmente adivinha aleatoriamente de acordo com a frequência de cada classe:\n",
        "\n",
        "      k = (Po - Pe)/(1-Pe) = 1 - (1 - Po)/(1 - Pe)\n",
        "\n",
        "Po é a concordancia observada e Pe é a concordância esperada. O Kappa de Cohen é sempre menor ou igual a 1, sendo que valores menores ou iguais a zero indicam que o classificador é inútil. Quanto mais próximo de 1, indica que o classificador gera uma concordância quase perfeita.\n",
        "\n",
        "* **Média Geométrica (G-mean)** é uma métrica que mede o equilíbrio entre o desempenho de classificação tanto na classe majoritária quanto na minoritária. Um índice baixo é uma indicação de mau desempenho na classificação dos casos positivos, mesmo que os casos negativos sejam corretamente classificados como tal. Ela é importante para prever o sobreajustamento da classe negativa e o subajustamento da classe positiva. Como nosso dataset não possui classes binárias, a fórmula de cálculo será como se segue (material de aula do Prof. André):\n",
        "\n",
        "      G-mean = $(\\pi_{i=1}^{c}Revocacao_{i})^{1/c}$ \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygXxE2fnYlY9"
      },
      "source": [
        "def calcula_especificidade(matriz_confusao):\n",
        "  FP = matriz_confusao.sum(axis=0) - np.diag(matriz_confusao) \n",
        "  FN = matriz_confusao.sum(axis=1) - np.diag(matriz_confusao)\n",
        "  VP = np.diag(matriz_confusao)\n",
        "  VN = matriz_confusao.sum() - (FP + FN + VP)\n",
        "  FP = FP.astype(float)\n",
        "  FN = FN.astype(float)\n",
        "  VP = VP.astype(float)\n",
        "  VN = VN.astype(float)\n",
        "  TVN = np.sum(VN)/(np.sum(VN) + np.sum(FP))\n",
        "  return TVN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTRdzPfNUmW4"
      },
      "source": [
        "def calcula_especificidade_porClasse(matriz_confusao):\n",
        "  FP = matriz_confusao.sum(axis=0) - np.diag(matriz_confusao) \n",
        "  FN = matriz_confusao.sum(axis=1) - np.diag(matriz_confusao)\n",
        "  VP = np.diag(matriz_confusao)\n",
        "  VN = matriz_confusao.sum() - (FP + FN + VP)\n",
        "  FP = FP.astype(float)\n",
        "  FN = FN.astype(float)\n",
        "  VP = VP.astype(float)\n",
        "  VN = VN.astype(float)\n",
        "  TVN = (VN)/(VN + FP)\n",
        "  return TVN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNfF5dTGibJe"
      },
      "source": [
        "def calcula_GMean_multiclass(revocacao):\n",
        "   revoc = np.array(revocacao)\n",
        "   GMean = revoc.prod()**(1.0/len(revoc))\n",
        "   return GMean  \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZR9epC7bOAj"
      },
      "source": [
        "def elabora_relatorio_metricas(report, matriz_confusao):\n",
        "  espec = calcula_especificidade_porClasse(matriz_confusao) # calcula o valor da especificidade para cada classe\n",
        "  dfrep = pd.DataFrame(report).transpose() #transforma o conteúdo do classification_report em um dataframe pandas\n",
        "  dfrep_a = dfrep[:-3].copy() # separa as métricas de cada classe do valor da acurácia geral do modelo\n",
        "  dfrep_a['specificity'] = espec # inclui no dataframe o valor da especificidade\n",
        "  dfrep_b  = dfrep[dfrep.index=='accuracy'].copy() #obtem do dataframe somente o valor da acurácia\n",
        "  dfrep_b['specificity']=calcula_especificidade(matriz_confusao) # inclui o valor da especificidade geral de todas as classes\n",
        "  metricas = ['precision', 'recall', 'specificity', 'f1-score', 'support'] #organiza as métricas na ordem desejada\n",
        "  df = pd.concat([dfrep_a[metricas],dfrep_b[metricas]],sort=False) #concatena todos os valores em um único dataframe\n",
        "  df['support'] = df['support'].astype('int')\n",
        "  return df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sGfCMMB9ewJ"
      },
      "source": [
        "def evaluate(model, test_loader, report=True):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    X = []\n",
        "\n",
        "\n",
        "    #obtem os valores preditos e os valores de teste\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (text, labels), _ in test_loader:\n",
        "                labels = labels.type(torch.LongTensor)  #carrega as classes para uma estrutura pytorch         \n",
        "                labels = labels.to(device)  #carrega a estrutura pytorch para GPU (se houver, foi testado anteriormente)\n",
        "                text = text.type(torch.LongTensor)    #carrega o texto para uma estrutura pytorch\n",
        "                text = text.to(device)          #carrega a estrutura pytorch para GPU (se houver, foi testado anteriormente)\n",
        "                output = model(text, labels)   #submete o texto e a label da classe ao modelo\n",
        "\n",
        "                _, output = output\n",
        "                y_pred.extend(torch.argmax(output, 1).tolist())  #obtem do pytorch de saída do modelo o valor predito.\n",
        "                y_true.extend(labels.tolist()) #obtem do pytorch de teste  valor real.\n",
        "                #print(_)\n",
        "                X.extend(output.tolist())\n",
        "    if report==False:\n",
        "      return [X, y_true, y_pred]\n",
        "\n",
        "    print('Classification Report:')\n",
        "    n_classe = np.max(y_true)+1 #obtem o número de classes\n",
        "    report = classification_report(y_true, y_pred, labels=np.arange(0,n_classe), digits=4, output_dict=True) #gera o relatório de métricas\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(0,n_classe)) #gera a matriz de confusao\n",
        "    report = elabora_relatorio_metricas(report, cm) #inclui no relatorio a especificidade\n",
        "    print(report)\n",
        "\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred,labels=np.arange(0,n_classe))\n",
        "    ccmatheus = matthews_corrcoef(y_true, y_pred)\n",
        "    \n",
        "    print(\"Acurácia:\",accuracy_score(y_true, y_pred))\n",
        "    print('Acurácia balanceada:',balanced_accuracy_score(y_true, y_pred))\n",
        "    print('GMean:', calcula_GMean_multiclass(report['recall']))\n",
        "    print('Cohen Kappa Score:', cohen_kappa)\n",
        "    print('Coef. Correlacao Matheus:', ccmatheus)\n",
        "    print('******************************************************************')\n",
        "    \n",
        "    \n",
        "    #ax= plt.subplot()\n",
        "    #sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "    #ax.set_title('Confusion Matrix')\n",
        "    #ax.set_xlabel('Predicted Labels')\n",
        "    #ax.set_ylabel('True Labels')\n",
        "    return [X, y_true, y_pred]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5g9qV-7OZ5X"
      },
      "source": [
        "#%%time    \n",
        "\n",
        "qtd_categories=[10,10,10,10]\n",
        "id_planilha = [9,9.1,9.2,9.3]\n",
        "MAX_SEQ_LEN = [128,256,512,256]\n",
        "dataset = [5,5,5,5]\n",
        "fig, ax =plt.subplots(2,2)\n",
        "corte=1\n",
        "for idx, (id_, amostra) in enumerate(zip(id_planilha,dataset)):\n",
        "      print('id_planilha:', id_)\n",
        "      label_field, text_field, fields = montaFields(MAX_SEQ_LEN[idx])\n",
        "      tokens = tokenizaAmostra(source_folder+str(amostra),soTeste=True)\n",
        "      best_model = BERT(qtd_categories=qtd_categories[idx]).to(device)\n",
        "      load_checkpoint(destination_folder+\"/\"+str(id_) + '/model.pt', best_model)\n",
        "      X_saida_teste, y_true, y_pred = evaluate(best_model, tokens[2]) #tokens[2] é o dataset de teste\n",
        "      X_saida_teste = np.array(X_saida_teste)\n",
        "      tsne = TSNE(n_components=2,perplexity=20, metric='euclidean', n_iter=1000, random_state=27, verbose=1)\n",
        "      X_embedded = tsne.fit_transform(X_saida_teste)\n",
        "      if idx<=corte:\n",
        "        i,j=0,idx\n",
        "      else:\n",
        "        i,j=1,idx-corte-1\n",
        "      sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette, ax=ax[i,j])\n",
        "      ax[i,j].set_title(id_)\n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SQ7PJAseK2n"
      },
      "source": [
        "#X, y_true, y_pred = resp\n",
        "#X = X.cpu().numpy()\n",
        "#X.shape\n",
        "#y = y_true.cpu().numpy()\n",
        "id_=9\n",
        "X = load_embedding(destination_folder+\"/\"+str(id_) + '/embedd.pt')\n",
        "X = X['_']\n",
        "X_saida_treino = np.array(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_URuVh2U9VT"
      },
      "source": [
        "print(X_saida_treino.shape)\n",
        "X_saida_treino[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv3uPQZbT43V"
      },
      "source": [
        "#y_treino\n",
        "id_amostra = 5\n",
        "df = pd.read_csv('./amostra_news_integrada/amostra_'+str(id_amostra)+'/train.csv')\n",
        "y = df['category_nro'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGTLjVHIleV6"
      },
      "source": [
        "Treino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtRVB-OZedQJ"
      },
      "source": [
        "tsne = TSNE(n_components=2,perplexity=20, metric='euclidean', n_iter=1000, random_state=27, verbose=1)\n",
        "X_embedded = tsne.fit_transform(X_saida_treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vVH-nB9WbP2"
      },
      "source": [
        "print(X_embedded.shape, len(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOlyu-A_fvjr"
      },
      "source": [
        "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full', palette=palette)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub1O1FrAOfTm"
      },
      "source": [
        "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
        "ax.scatter(\n",
        "    xs=X_embedded[:,0], \n",
        "    ys=X_embedded[:,1], \n",
        "    zs=X_embedded[:,2], \n",
        "    c=y \n",
        "    \n",
        ")\n",
        "ax.set_xlabel('x-one')\n",
        "ax.set_ylabel('x-two')\n",
        "ax.set_zlabel('x-three')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdXCYxALluwf"
      },
      "source": [
        "Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcFTDtUwk7y5"
      },
      "source": [
        "X_saida_teste = np.array(X_saida_teste)\n",
        "print(X_saida_teste.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxl619hKluDi"
      },
      "source": [
        "tsne = TSNE(n_components=2,perplexity=20, metric='euclidean', n_iter=1000, random_state=27, verbose=1)\n",
        "X_embedded = tsne.fit_transform(X_saida_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5z2NTMTl3bf"
      },
      "source": [
        "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJrH6W-UEXCK"
      },
      "source": [
        ""
      ]
    }
  ]
}